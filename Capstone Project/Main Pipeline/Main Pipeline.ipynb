{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis of Ethiopia Reviews with Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following pipeline will show a step-by-step approach of our project methodology. The explanations for the code can be seen in markdown below the code snippets they are respectively referring to.\n",
    "<br>\n",
    "<br>Notes:<br>\n",
    "<ul>\n",
    "    <li>Only English Reviews were scraped from TripAdvisor</li>\n",
    "    <li>Only three (3) Destination Types were used in this methodology</li>\n",
    "    <li>The other notebooks from the other folders are either fragments of this main pipeline or iterations that did not produce promising results</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "<ul>\n",
    "    <li><a href=\"#importing_modules\">Importing Modules</a></li>\n",
    "    <li><a href=\"#web_scraping\">Web Scraping</a></li>\n",
    "    <ul>\n",
    "        <li><a href=\"#web_scraping1\">Getting all Initial Review Pages from all wanted Tourist Destinations</a></li>\n",
    "        <li><a href=\"#web_scraping2\">Getting All Review Pages from Initial Pages</a></li>\n",
    "        <li><a href=\"#web_scraping3\">Getting all Reviews from all Review Pages</a></li>\n",
    "    </ul>\n",
    "    <li><a href=\"#data_preprocessing\">Data Preprocessing</a></li>\n",
    "    <ul>\n",
    "        <li><a href=\"#data_preprocessing1\">Data Cleaning</a></li>\n",
    "        <li><a href=\"#data_preprocessing2\">Feature Engineering</a></li>\n",
    "    </ul>\n",
    "    <li><a href=\"#conclusion\">Topic Modelling</a></li>\n",
    "</ul>\n",
    "    \n",
    "</div>\n",
    " \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='importing_modules'></a>\n",
    "### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\nltk\\decorators.py:68: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  regargs, varargs, varkwargs, defaults, formatvalue=lambda value: \"\"\n",
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\nltk\\lm\\counter.py:15: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sequence, defaultdict\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import collections\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  \n",
    "\n",
    "import spacy\n",
    "from spacy.lemmatizer import Lemmatizer\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "headers = requests.utils.default_headers()\n",
    "headers.update({\n",
    "    'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0',\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='web_scraping'></a>\n",
    "### Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='web_scraping1'></a>\n",
    "**Getting all Initial Review Pages from all wanted Tourist Destinations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Three Main Destination Types:\n",
    "# Sights and Landmarks\n",
    "# Nature and Parks\n",
    "# Museums\n",
    "site_category_list = ['https://www.tripadvisor.com.ph/Attractions-g293790-Activities-c47-t2,3,10,15,17,19,26,76,163,175-Ethiopia.html', # Sights and Landmarks\n",
    "                    'https://www.tripadvisor.com.ph/Attractions-g293790-Activities-c57-t57,66,67,68,70-Ethiopia.html', # Nature and Parks\n",
    "                     'https://www.tripadvisor.com.ph/Attractions-g293790-Activities-c49-t1,28,29,30,161-Ethiopia.html'] # Museums\n",
    "skipped_urls = []\n",
    "first_page_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above list of URLs encompasses all the tourist destinations of interest. This, of course, can easily be modified just in case you want to scrape destinations from different countries, destination types, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFirstPages(x):\n",
    "    for i in x:\n",
    "        page = requests.get(i)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        sites = soup.find_all(class_ = 'attraction_element')\n",
    "        for j in sites:\n",
    "            if j.find(class_ = 'rs rating') != None:\n",
    "                first_page_list.append('https://www.tripadvisor.com.ph/' + j.find(class_ = 'listing_title').a.get('href'))\n",
    "        if len(sites) == 0 and i not in skipped_urls:\n",
    "            skipped_urls.append(i)\n",
    "        if len(sites) > 0 and i in skipped_urls:\n",
    "            skipped_urls.remove(i)\n",
    "        print('skipped: ', skipped_urls)\n",
    "        time.sleep(random.uniform(15, 30))\n",
    "    if len(skipped_urls) != 0:\n",
    "        print('restarting function...')\n",
    "        getFirstPages(skipped_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code will iterate over all the destinations present within the _site_category_list_ URLs and get their respective href attributes to get all the first review pages of the destinations. Since sometimes requests from Beautiful Soup fail to get data from the web page, the function is recursive so that in the case that URLs are skipped, they will be fed again to the function. This feature will be present in future scraping code as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getFirstPages(site_category_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting all first pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_first_page_list = []\n",
    "for i in range(len(first_page_list)):\n",
    "    final_first_page_list.append(first_page_list[i][0:30] + first_page_list[i][31:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code removes the double slash after \"tripadvisor.com.ph\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='web_scraping2'></a>\n",
    "**Getting All Review Pages from Initial Pages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_url_list = []\n",
    "skipped_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFinalList(x):\n",
    "    for i in x:\n",
    "        page_nos = []\n",
    "        print('site: ', i)\n",
    "        page = requests.get(i, headers = headers)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        readcheck = soup.find_all(class_ = 'count')\n",
    "        print('readcheck: ', len(readcheck))\n",
    "        for j in soup.find_all('a'):\n",
    "            if j.get('data-page-number') != None and readcheck != 0:\n",
    "                page_nos.append(j.get('data-page-number'))\n",
    "            elif j.get('data-page-number') == None and readcheck != 0:\n",
    "                page_nos.append(0)\n",
    "        if len(readcheck) == 0:\n",
    "            page_nos = []\n",
    "        page_nos = list(map(int, page_nos))\n",
    "        if len(page_nos) > 0:\n",
    "            final_url_list.append(i)\n",
    "            if max(page_nos) > 0:\n",
    "                getReviewPages(i, max(page_nos))\n",
    "        if len(page_nos) == 0 and i not in skipped_urls:\n",
    "            skipped_urls.append(i)\n",
    "        if len(page_nos) > 0 and i in skipped_urls:\n",
    "            skipped_urls.remove(i)\n",
    "        print('skipped: ', skipped_urls)\n",
    "        time.sleep(random.uniform(15, 30))\n",
    "    if len(skipped_urls) != 0:\n",
    "        print('restarting function...')\n",
    "        getFinalList(skipped_urls)\n",
    "        \n",
    "def getReviewPages(x, y):\n",
    "    pre = re.findall('https://www.tripadvisor.com.ph/Attraction_Review-\\w\\d+-\\w\\d+-Reviews-' , x)\n",
    "    post = re.findall('Reviews-\\D+' , x)\n",
    "    print(len(pre))\n",
    "    print(len(post))\n",
    "    review_pages = ((pre[0] + 'or{}' + post[0].replace('Reviews', '')).format(j) for j in range(10, y*10, 10))\n",
    "    final_url_list.extend(review_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code iterates over all first review pages acquired earlier, checks for the respective number of pages for each destination, and returns all the URLs needed for the main data scraping sequence later. Regular Expressions were used to properly construct subsequent URLs as they follow a pattern after the first pages. Again, it is recursive in nature to take into consideration the skipped URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getFinalList(final_first_page_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting all URLs of Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_url_list = list(set(final_url_list)) # All needed URLs to be scraped (no duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing all duplicates just in case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='web_scraping3'></a>\n",
    "**Getting all Reviews from all Review Pages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_place_list = []\n",
    "rev_head_list = []\n",
    "rev_body_list = []\n",
    "rev_rating_list = []\n",
    "rev_date_list = []\n",
    "skipped_urls = []\n",
    "ignored_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPlace(x, y):\n",
    "    for i in y.find_all(class_ = 'noQuotes'):\n",
    "        rev_place_list.append(x.find(id = 'HEADING').string)\n",
    "\n",
    "def getHead(x):\n",
    "    for i in x.find_all(class_ = 'noQuotes'):\n",
    "        rev_head_list.append(i.string)\n",
    "\n",
    "def getBody(x):\n",
    "    z = x.find_all(class_ = 'entry')\n",
    "    for i in z:\n",
    "        if i.find(class_ = 'taLnk ulBlueLinks') != None:\n",
    "            rev_body_list.append(i.text[:-4])\n",
    "        else:\n",
    "            rev_body_list.append(i.text)\n",
    "\n",
    "def getRating(x):\n",
    "    rev_revs = x.find_all(class_='ui_column is-9')\n",
    "    for i in range(len(rev_revs)):\n",
    "        if rev_revs[i].find(class_ = 'ui_bubble_rating bubble_50') != None:\n",
    "            rev_rating_list.append(5)\n",
    "        elif rev_revs[i].find(class_ = 'ui_bubble_rating bubble_40') != None:\n",
    "            rev_rating_list.append(4)\n",
    "        elif rev_revs[i].find(class_ = 'ui_bubble_rating bubble_30') != None:\n",
    "            rev_rating_list.append(3)\n",
    "        elif rev_revs[i].find(class_ = 'ui_bubble_rating bubble_20') != None:\n",
    "            rev_rating_list.append(2)\n",
    "        elif rev_revs[i].find(class_ = 'ui_bubble_rating bubble_10') != None:\n",
    "            rev_rating_list.append(1)\n",
    "\n",
    "def getDate(x):\n",
    "    for i in x.find_all(class_ = 'prw_rup prw_reviews_stay_date_hsx'):\n",
    "        if i.find(class_ = 'stay_date_label') == None:\n",
    "            rev_date_list.append('None')\n",
    "        else:\n",
    "            rev_date_list.append(str(i.span.next_sibling).strip())\n",
    "\n",
    "def delay(x, y):\n",
    "    time.sleep(random.uniform(x, y))\n",
    "    return None\n",
    "\n",
    "def getData(urls):\n",
    "    start_revs_head = 0\n",
    "    end_revs_head = 0\n",
    "    start_revs_body = 0\n",
    "    end_revs_body = 0\n",
    "    for i in urls:\n",
    "        start_revs_head = len(rev_head_list)\n",
    "        start_revs_body = len(rev_body_list)\n",
    "        print('start head: ', len(rev_head_list), 'start body: ', len(rev_body_list))\n",
    "        page = requests.get(i, headers = headers)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        rev = soup.find(id = 'REVIEWS')\n",
    "        getHead(rev)\n",
    "        getBody(rev)\n",
    "        end_revs_head = len(rev_head_list)\n",
    "        end_revs_body = len(rev_body_list)\n",
    "        print('end head: ', len(rev_head_list), 'end body: ', len(rev_body_list))\n",
    "        if len(rev_head_list) != len(rev_body_list):\n",
    "            print('ignoring url...')\n",
    "            ignored_urls.append(i)\n",
    "            del rev_head_list[- (end_revs_head - start_revs_head):]\n",
    "            del rev_body_list[- (end_revs_body - start_revs_body):]\n",
    "            continue\n",
    "        if end_revs_head == start_revs_head and i not in skipped_urls:\n",
    "            skipped_urls.append(i)\n",
    "        if end_revs_head > start_revs_head and i in skipped_urls:\n",
    "            skipped_urls.remove(i)\n",
    "        print('skipped URL count: ', len(skipped_urls))\n",
    "        getPlace(soup, rev)\n",
    "        getRating(rev)\n",
    "        getDate(rev)\n",
    "        delay(5, 15)\n",
    "    if len(skipped_urls) != 0:\n",
    "        print('restarting function...')\n",
    "        getData(skipped_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code iterates over all of the review page URLs and gets the review data from each page. The  five (5) following features were the main data of interest:\n",
    "<ul>\n",
    "    <li>Destination Name</li>\n",
    "    <li>Review Head</li>\n",
    "    <li>Review Body</li>\n",
    "    <li>Rating</li>\n",
    "    <li>Date of Experience</li>\n",
    "</ul>\n",
    "<br>Again, it is recursive in nature to take into consideration the skipped URLs. Also, there are instances where some people would reply to a review and should this happen in a review page URL, the code ignores the URL since it will treat the reply as a review body and it will cause a mismatch between the counts of review heads and review bodies. Not much data is lost in this case as, if I recall correctly, there were only three (3) ignored URLs that showed reviews with replies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getData(final_url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting all the needed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(rev_place_list))\n",
    "print(len(rev_head_list))\n",
    "print(len(rev_body_list))\n",
    "print(len(rev_rating_list))\n",
    "print(len(rev_date_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the counts for all five (5) features match (they should)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_preprocessing'></a>\n",
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_preprocessing1'></a>\n",
    "**Data Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({'Destination Name': rev_place_list, 'Review Head': rev_head_list, 'Review Body': rev_body_list, 'Rating': rev_rating_list, 'Date': rev_date_list})\n",
    "df1 = df1.drop_duplicates()\n",
    "df1['Destination Name'] = df1['Destination Name'].replace(to_replace = 'Chebera-Churchura National Park', \n",
    "                                                               value = 'Chebera Churchura National Park')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates a dataframe from the five (5) lists acquired earlier via scraping. It also drops duplicates.\n",
    "There were instances of the destination \"Chebera Churchura National Park\" with an extra hyphen so they were replaced accordingly for the sake of formality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['Monastery of Debre Damo'] # this site was removed from the initial URLs for some reason since our first scraping \n",
    "nature_parks = []\n",
    "museums = []\n",
    "\n",
    "def getDestinationsByType(x):\n",
    "    for i in range(len(x)):\n",
    "        page = requests.get(x[i])\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "        sites = soup.find_all(class_ = 'attraction_element')\n",
    "        for j in sites:\n",
    "            k = j.find(class_ = 'listing_title').text\n",
    "            k = re.sub(\"^\\s+\", \"\", k)\n",
    "            k = re.sub(\"\\s+$\", \"\", k)\n",
    "            k = re.sub(\"\\s+.+$\", \"\", k)\n",
    "            if i == 0:\n",
    "                landmarks.append(k)\n",
    "            elif i == 1:\n",
    "                nature_parks.append(k)\n",
    "            elif i == 2:\n",
    "                museums.append(k)\n",
    "        time.sleep(random.uniform(5, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code iterates over all the destinations from the initial _site_category_list_ URLs and filters them accordingly into lists of the three destination types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getDestinationsByType(site_category_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling up the lists - _landmarks_ + _nature_parks_ + _museums_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def destinationType(row):\n",
    "    if row['Destination Name'] in landmarks:\n",
    "        return 'Landmarks'\n",
    "    elif row['Destination Name'] in nature_parks:\n",
    "        return 'Nature/Parks'\n",
    "    elif row['Destination Name'] in museums:\n",
    "        return 'Museums'\n",
    "    \n",
    "df1['Destination Type'] = df1.apply(destinationType, axis = 1)\n",
    "df1.head() # df1 is now the first main checkpoint dataframe gotten from scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates the _Destination Type_ feature and iterates over all the _Destination Names_ to classify them.\n",
    "<br>df1 is now the main checkpoint dataframe that is already ready for different use cases and subsequent changes are now based on the methodology to be applied.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Name</th>\n",
       "      <th>Destination Type</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Head</th>\n",
       "      <th>Review Body</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>5</td>\n",
       "      <td>Incredible locations don't be put off thinking...</td>\n",
       "      <td>Amazing location must visit. This site is mark...</td>\n",
       "      <td>October 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>5</td>\n",
       "      <td>It is a real miracle of the world!</td>\n",
       "      <td>I do recommend to visit Lalibela churches and ...</td>\n",
       "      <td>October 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>5</td>\n",
       "      <td>Incredible experience</td>\n",
       "      <td>A must visit in Ethiopia - one of the most uni...</td>\n",
       "      <td>October 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>4</td>\n",
       "      <td>Amazing</td>\n",
       "      <td>These churches have to be seen to be believed....</td>\n",
       "      <td>October 2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>5</td>\n",
       "      <td>So much history</td>\n",
       "      <td>Thanks to our tour organiser Ephram who is bas...</td>\n",
       "      <td>October 2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Destination Name Destination Type  Rating  \\\n",
       "0  Rock-Hewn Churches of Lalibela        Landmarks       5   \n",
       "1  Rock-Hewn Churches of Lalibela        Landmarks       5   \n",
       "2  Rock-Hewn Churches of Lalibela        Landmarks       5   \n",
       "3  Rock-Hewn Churches of Lalibela        Landmarks       4   \n",
       "4  Rock-Hewn Churches of Lalibela        Landmarks       5   \n",
       "\n",
       "                                         Review Head  \\\n",
       "0  Incredible locations don't be put off thinking...   \n",
       "1                 It is a real miracle of the world!   \n",
       "2                             Incredible experience    \n",
       "3                                            Amazing   \n",
       "4                                    So much history   \n",
       "\n",
       "                                         Review Body          Date  \n",
       "0  Amazing location must visit. This site is mark...  October 2019  \n",
       "1  I do recommend to visit Lalibela churches and ...  October 2019  \n",
       "2  A must visit in Ethiopia - one of the most uni...  October 2019  \n",
       "3  These churches have to be seen to be believed....  October 2019  \n",
       "4  Thanks to our tour organiser Ephram who is bas...  October 2019  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('ethiopia_tripadvisor_data_1.csv') # df2 is the same as df1 (we just saved it before into a csv file)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, we already scraped the data beforehand into a csv file, the above code will call it instead of re-running the web scraping pipeline above \n",
    "(of course, you are open to make scraping modifications above depending on your possible future use case).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Name</th>\n",
       "      <th>Destination Type</th>\n",
       "      <th>Review Head</th>\n",
       "      <th>Review Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>Incredible locations don't be put off thinking...</td>\n",
       "      <td>Amazing location must visit. This site is mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>It is a real miracle of the world!</td>\n",
       "      <td>I do recommend to visit Lalibela churches and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>Incredible experience</td>\n",
       "      <td>A must visit in Ethiopia - one of the most uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>Amazing</td>\n",
       "      <td>These churches have to be seen to be believed....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>So much history</td>\n",
       "      <td>Thanks to our tour organiser Ephram who is bas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Destination Name Destination Type  \\\n",
       "0  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "1  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "2  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "3  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "4  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "\n",
       "                                         Review Head  \\\n",
       "0  Incredible locations don't be put off thinking...   \n",
       "1                 It is a real miracle of the world!   \n",
       "2                             Incredible experience    \n",
       "3                                            Amazing   \n",
       "4                                    So much history   \n",
       "\n",
       "                                         Review Body  \n",
       "0  Amazing location must visit. This site is mark...  \n",
       "1  I do recommend to visit Lalibela churches and ...  \n",
       "2  A must visit in Ethiopia - one of the most uni...  \n",
       "3  These churches have to be seen to be believed....  \n",
       "4  Thanks to our tour organiser Ephram who is bas...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.mask(df2.eq('None')).dropna()\n",
    "df2 = df2.drop(['Rating', 'Date'], axis = 1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code removes the _Rating_ and _Date_ features since they are not part of the methodology in this pipeline. They are, however, used in the other notebooks for Exploratory Data Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Destination Name    0\n",
      "Destination Type    0\n",
      "Review Head         0\n",
      "Review Body         0\n",
      "dtype: int64\n",
      "Destination Name    0\n",
      "Destination Type    0\n",
      "Review Head         0\n",
      "Review Body         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df2 = df2.drop_duplicates()\n",
    "print(df2.duplicated().sum())\n",
    "print(df2.isnull().sum())\n",
    "print(df2.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8310 entries, 0 to 8412\n",
      "Data columns (total 4 columns):\n",
      "Destination Name    8310 non-null object\n",
      "Destination Type    8310 non-null object\n",
      "Review Head         8310 non-null object\n",
      "Review Body         8310 non-null object\n",
      "dtypes: object(4)\n",
      "memory usage: 324.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data_preprocessing2'></a>\n",
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Name</th>\n",
       "      <th>Destination Type</th>\n",
       "      <th>Review Head</th>\n",
       "      <th>Review Body</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>RB_Sentence1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>Incredible locations don't be put off thinking...</td>\n",
       "      <td>Amazing location must visit. This site is mark...</td>\n",
       "      <td>Incredible locations don't be put off thinking...</td>\n",
       "      <td>Amazing location must visit.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>It is a real miracle of the world!</td>\n",
       "      <td>I do recommend to visit Lalibela churches and ...</td>\n",
       "      <td>It is a real miracle of the world! I do recomm...</td>\n",
       "      <td>I do recommend to visit Lalibela churches and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>Incredible experience</td>\n",
       "      <td>A must visit in Ethiopia - one of the most uni...</td>\n",
       "      <td>Incredible experience A must visit in Ethiopia...</td>\n",
       "      <td>A must visit in Ethiopia - one of the most uni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>Amazing</td>\n",
       "      <td>These churches have to be seen to be believed....</td>\n",
       "      <td>Amazing These churches have to be seen to be b...</td>\n",
       "      <td>These churches have to be seen to be believed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>So much history</td>\n",
       "      <td>Thanks to our tour organiser Ephram who is bas...</td>\n",
       "      <td>So much history Thanks to our tour organiser E...</td>\n",
       "      <td>Thanks to our tour organiser Ephram who is bas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Destination Name Destination Type  \\\n",
       "0  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "1  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "2  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "3  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "4  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "\n",
       "                                         Review Head  \\\n",
       "0  Incredible locations don't be put off thinking...   \n",
       "1                 It is a real miracle of the world!   \n",
       "2                             Incredible experience    \n",
       "3                                            Amazing   \n",
       "4                                    So much history   \n",
       "\n",
       "                                         Review Body  \\\n",
       "0  Amazing location must visit. This site is mark...   \n",
       "1  I do recommend to visit Lalibela churches and ...   \n",
       "2  A must visit in Ethiopia - one of the most uni...   \n",
       "3  These churches have to be seen to be believed....   \n",
       "4  Thanks to our tour organiser Ephram who is bas...   \n",
       "\n",
       "                                         Review Text  \\\n",
       "0  Incredible locations don't be put off thinking...   \n",
       "1  It is a real miracle of the world! I do recomm...   \n",
       "2  Incredible experience A must visit in Ethiopia...   \n",
       "3  Amazing These churches have to be seen to be b...   \n",
       "4  So much history Thanks to our tour organiser E...   \n",
       "\n",
       "                                        RB_Sentence1  \n",
       "0                       Amazing location must visit.  \n",
       "1  I do recommend to visit Lalibela churches and ...  \n",
       "2  A must visit in Ethiopia - one of the most uni...  \n",
       "3     These churches have to be seen to be believed.  \n",
       "4  Thanks to our tour organiser Ephram who is bas...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Review Text'] = df2['Review Head'] + ' ' + df2['Review Body'] # Review Text = Review Head + Review Body\n",
    "df2['RB_Sentence1'] = df2['Review Body'].apply(lambda x: tokenize.sent_tokenize(x)[0]) # RB_Sentence 1 = Review Body Sentence 1\n",
    "df2['Review Head'] = df2['Review Head'].apply(lambda x: re.sub('\\s+', ' ', x))\n",
    "df2['Review Body'] = df2['Review Body'].apply(lambda x: re.sub('\\s+', ' ', x))\n",
    "df2['Review Text'] = df2['Review Text'].apply(lambda x: re.sub('\\s+', ' ', x))\n",
    "df2['RB_Sentence1'] = df2['RB_Sentence1'].apply(lambda x: re.sub('\\s+', ' ', x))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates the _Review Text_ and _RB_Sentence1_ feature where:\n",
    "<li>Review Text = Review Head + Review Body</li>\n",
    "<li>RB_Sentence 1 = Review Body Sentence 1</li>\n",
    "<br>The Review Body Sentence 1 feature was made under the assumption that the main message of the tourist's review is based on the first sentence of the review body. What we found out as we progress towards Topic Modelling is that Review Head and Review Body Sentence 1 showed the best results both in the coherence score metric and the topics being more identifiable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Name</th>\n",
       "      <th>Destination Type</th>\n",
       "      <th>Review Head</th>\n",
       "      <th>Review Body</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>RB_Sentence1</th>\n",
       "      <th>TextBlob Polarity Head</th>\n",
       "      <th>TextBlob Polarity Body</th>\n",
       "      <th>TextBlob Polarity Text</th>\n",
       "      <th>TextBlob Polarity RBS1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>Incredible locations don't be put off thinking...</td>\n",
       "      <td>Amazing location must visit. This site is mark...</td>\n",
       "      <td>Incredible locations don't be put off thinking...</td>\n",
       "      <td>Amazing location must visit.</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>It is a real miracle of the world!</td>\n",
       "      <td>I do recommend to visit Lalibela churches and ...</td>\n",
       "      <td>It is a real miracle of the world! I do recomm...</td>\n",
       "      <td>I do recommend to visit Lalibela churches and ...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.016667</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>Incredible experience</td>\n",
       "      <td>A must visit in Ethiopia - one of the most uni...</td>\n",
       "      <td>Incredible experience A must visit in Ethiopia...</td>\n",
       "      <td>A must visit in Ethiopia - one of the most uni...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.483750</td>\n",
       "      <td>0.4375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>Amazing</td>\n",
       "      <td>These churches have to be seen to be believed....</td>\n",
       "      <td>Amazing These churches have to be seen to be b...</td>\n",
       "      <td>These churches have to be seen to be believed.</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>So much history</td>\n",
       "      <td>Thanks to our tour organiser Ephram who is bas...</td>\n",
       "      <td>So much history Thanks to our tour organiser E...</td>\n",
       "      <td>Thanks to our tour organiser Ephram who is bas...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Destination Name Destination Type  \\\n",
       "0  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "1  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "2  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "3  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "4  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "\n",
       "                                         Review Head  \\\n",
       "0  Incredible locations don't be put off thinking...   \n",
       "1                 It is a real miracle of the world!   \n",
       "2                             Incredible experience    \n",
       "3                                            Amazing   \n",
       "4                                    So much history   \n",
       "\n",
       "                                         Review Body  \\\n",
       "0  Amazing location must visit. This site is mark...   \n",
       "1  I do recommend to visit Lalibela churches and ...   \n",
       "2  A must visit in Ethiopia - one of the most uni...   \n",
       "3  These churches have to be seen to be believed....   \n",
       "4  Thanks to our tour organiser Ephram who is bas...   \n",
       "\n",
       "                                         Review Text  \\\n",
       "0  Incredible locations don't be put off thinking...   \n",
       "1  It is a real miracle of the world! I do recomm...   \n",
       "2  Incredible experience A must visit in Ethiopia...   \n",
       "3  Amazing These churches have to be seen to be b...   \n",
       "4  So much history Thanks to our tour organiser E...   \n",
       "\n",
       "                                        RB_Sentence1  TextBlob Polarity Head  \\\n",
       "0                       Amazing location must visit.                   -0.05   \n",
       "1  I do recommend to visit Lalibela churches and ...                    0.25   \n",
       "2  A must visit in Ethiopia - one of the most uni...                    0.90   \n",
       "3     These churches have to be seen to be believed.                    0.60   \n",
       "4  Thanks to our tour organiser Ephram who is bas...                    0.20   \n",
       "\n",
       "   TextBlob Polarity Body  TextBlob Polarity Text  TextBlob Polarity RBS1  \n",
       "0                0.300000                0.125000                  0.6000  \n",
       "1               -0.150000               -0.016667                  0.0000  \n",
       "2                0.345000                0.483750                  0.4375  \n",
       "3                0.225000                0.350000                  0.0000  \n",
       "4                0.233333                0.228571                  0.2000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['TextBlob Polarity Head'] = df2['Review Head'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
    "df2['TextBlob Polarity Body'] = df2['Review Body'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
    "df2['TextBlob Polarity Text'] = df2['Review Text'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
    "df2['TextBlob Polarity RBS1'] = df2['RB_Sentence1'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code assigns polarities for the different Review Text Types via TextBlob. We chose this instead of the Rating feature/metric since Rating\n",
    "does a worse job in capturing sentiment (e.g. some reviews with high ratings have mixed sentiments within their reviews).\n",
    "<br>More of this from here:\n",
    "<li>https://econlife.com/2019/05/5-star-ratings-inflation/</li>\n",
    "<li>https://datascience.stanford.edu/news/story-rated-five-stars-new-study-finds-online-ratings-systems-words-are-more-accurate-stars-and</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Destination Name</th>\n",
       "      <th>Destination Type</th>\n",
       "      <th>Review Head</th>\n",
       "      <th>Review Body</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>RB_Sentence1</th>\n",
       "      <th>TextBlob Polarity Head</th>\n",
       "      <th>TextBlob Polarity Body</th>\n",
       "      <th>TextBlob Polarity Text</th>\n",
       "      <th>TextBlob Polarity RBS1</th>\n",
       "      <th>RH_Split</th>\n",
       "      <th>RB_Split</th>\n",
       "      <th>RT_Split</th>\n",
       "      <th>RB_Sentence1_Split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>Incredible locations don't be put off thinking...</td>\n",
       "      <td>Amazing location must visit. This site is mark...</td>\n",
       "      <td>Incredible locations don't be put off thinking...</td>\n",
       "      <td>Amazing location must visit.</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>[Incredible, locations, don't, be, put, off, t...</td>\n",
       "      <td>[Amazing, location, must, visit., This, site, ...</td>\n",
       "      <td>[Incredible, locations, don't, be, put, off, t...</td>\n",
       "      <td>[Amazing, location, must, visit.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>It is a real miracle of the world!</td>\n",
       "      <td>I do recommend to visit Lalibela churches and ...</td>\n",
       "      <td>It is a real miracle of the world! I do recomm...</td>\n",
       "      <td>I do recommend to visit Lalibela churches and ...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-0.016667</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>[It, is, a, real, miracle, of, the, world!]</td>\n",
       "      <td>[I, do, recommend, to, visit, Lalibela, church...</td>\n",
       "      <td>[It, is, a, real, miracle, of, the, world!, I,...</td>\n",
       "      <td>[I, do, recommend, to, visit, Lalibela, church...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>Incredible experience</td>\n",
       "      <td>A must visit in Ethiopia - one of the most uni...</td>\n",
       "      <td>Incredible experience A must visit in Ethiopia...</td>\n",
       "      <td>A must visit in Ethiopia - one of the most uni...</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.483750</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>[Incredible, experience, ]</td>\n",
       "      <td>[A, must, visit, in, Ethiopia, -, one, of, the...</td>\n",
       "      <td>[Incredible, experience, A, must, visit, in, E...</td>\n",
       "      <td>[A, must, visit, in, Ethiopia, -, one, of, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>Amazing</td>\n",
       "      <td>These churches have to be seen to be believed....</td>\n",
       "      <td>Amazing These churches have to be seen to be b...</td>\n",
       "      <td>These churches have to be seen to be believed.</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>[Amazing]</td>\n",
       "      <td>[These, churches, have, to, be, seen, to, be, ...</td>\n",
       "      <td>[Amazing, These, churches, have, to, be, seen,...</td>\n",
       "      <td>[These, churches, have, to, be, seen, to, be, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rock-Hewn Churches of Lalibela</td>\n",
       "      <td>Landmarks</td>\n",
       "      <td>So much history</td>\n",
       "      <td>Thanks to our tour organiser Ephram who is bas...</td>\n",
       "      <td>So much history Thanks to our tour organiser E...</td>\n",
       "      <td>Thanks to our tour organiser Ephram who is bas...</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>[So, much, history]</td>\n",
       "      <td>[Thanks, to, our, tour, organiser, Ephram, who...</td>\n",
       "      <td>[So, much, history, Thanks, to, our, tour, org...</td>\n",
       "      <td>[Thanks, to, our, tour, organiser, Ephram, who...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Destination Name Destination Type  \\\n",
       "0  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "1  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "2  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "3  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "4  Rock-Hewn Churches of Lalibela        Landmarks   \n",
       "\n",
       "                                         Review Head  \\\n",
       "0  Incredible locations don't be put off thinking...   \n",
       "1                 It is a real miracle of the world!   \n",
       "2                             Incredible experience    \n",
       "3                                            Amazing   \n",
       "4                                    So much history   \n",
       "\n",
       "                                         Review Body  \\\n",
       "0  Amazing location must visit. This site is mark...   \n",
       "1  I do recommend to visit Lalibela churches and ...   \n",
       "2  A must visit in Ethiopia - one of the most uni...   \n",
       "3  These churches have to be seen to be believed....   \n",
       "4  Thanks to our tour organiser Ephram who is bas...   \n",
       "\n",
       "                                         Review Text  \\\n",
       "0  Incredible locations don't be put off thinking...   \n",
       "1  It is a real miracle of the world! I do recomm...   \n",
       "2  Incredible experience A must visit in Ethiopia...   \n",
       "3  Amazing These churches have to be seen to be b...   \n",
       "4  So much history Thanks to our tour organiser E...   \n",
       "\n",
       "                                        RB_Sentence1  TextBlob Polarity Head  \\\n",
       "0                       Amazing location must visit.                   -0.05   \n",
       "1  I do recommend to visit Lalibela churches and ...                    0.25   \n",
       "2  A must visit in Ethiopia - one of the most uni...                    0.90   \n",
       "3     These churches have to be seen to be believed.                    0.60   \n",
       "4  Thanks to our tour organiser Ephram who is bas...                    0.20   \n",
       "\n",
       "   TextBlob Polarity Body  TextBlob Polarity Text  TextBlob Polarity RBS1  \\\n",
       "0                0.300000                0.125000                  0.6000   \n",
       "1               -0.150000               -0.016667                  0.0000   \n",
       "2                0.345000                0.483750                  0.4375   \n",
       "3                0.225000                0.350000                  0.0000   \n",
       "4                0.233333                0.228571                  0.2000   \n",
       "\n",
       "                                            RH_Split  \\\n",
       "0  [Incredible, locations, don't, be, put, off, t...   \n",
       "1        [It, is, a, real, miracle, of, the, world!]   \n",
       "2                         [Incredible, experience, ]   \n",
       "3                                          [Amazing]   \n",
       "4                                [So, much, history]   \n",
       "\n",
       "                                            RB_Split  \\\n",
       "0  [Amazing, location, must, visit., This, site, ...   \n",
       "1  [I, do, recommend, to, visit, Lalibela, church...   \n",
       "2  [A, must, visit, in, Ethiopia, -, one, of, the...   \n",
       "3  [These, churches, have, to, be, seen, to, be, ...   \n",
       "4  [Thanks, to, our, tour, organiser, Ephram, who...   \n",
       "\n",
       "                                            RT_Split  \\\n",
       "0  [Incredible, locations, don't, be, put, off, t...   \n",
       "1  [It, is, a, real, miracle, of, the, world!, I,...   \n",
       "2  [Incredible, experience, A, must, visit, in, E...   \n",
       "3  [Amazing, These, churches, have, to, be, seen,...   \n",
       "4  [So, much, history, Thanks, to, our, tour, org...   \n",
       "\n",
       "                                  RB_Sentence1_Split  \n",
       "0                  [Amazing, location, must, visit.]  \n",
       "1  [I, do, recommend, to, visit, Lalibela, church...  \n",
       "2  [A, must, visit, in, Ethiopia, -, one, of, the...  \n",
       "3  [These, churches, have, to, be, seen, to, be, ...  \n",
       "4  [Thanks, to, our, tour, organiser, Ephram, who...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['RH_Split'] = df2['Review Head'].apply(lambda x: x.split(' '))\n",
    "df2['RB_Split'] = df2['Review Body'].apply(lambda x: x.split(' '))\n",
    "df2['RT_Split'] = df2['Review Text'].apply(lambda x: x.split(' '))\n",
    "df2['RB_Sentence1_Split'] = df2['RB_Sentence1'].apply(lambda x: x.split(' '))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code splits the different Review Text Types into lists of words as features. This will be helpful later when removing positive and negative words for the text preprocessing stage before topic modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8310 entries, 0 to 8412\n",
      "Data columns (total 14 columns):\n",
      "Destination Name          8310 non-null object\n",
      "Destination Type          8310 non-null object\n",
      "Review Head               8310 non-null object\n",
      "Review Body               8310 non-null object\n",
      "Review Text               8310 non-null object\n",
      "RB_Sentence1              8310 non-null object\n",
      "TextBlob Polarity Head    8310 non-null float64\n",
      "TextBlob Polarity Body    8310 non-null float64\n",
      "TextBlob Polarity Text    8310 non-null float64\n",
      "TextBlob Polarity RBS1    8310 non-null float64\n",
      "RH_Split                  8310 non-null object\n",
      "RB_Split                  8310 non-null object\n",
      "RT_Split                  8310 non-null object\n",
      "RB_Sentence1_Split        8310 non-null object\n",
      "dtypes: float64(4), object(10)\n",
      "memory usage: 973.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Landmarks       3803\n",
       "Museums         2506\n",
       "Nature/Parks    2001\n",
       "Name: Destination Type, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['Destination Type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='topic_modelling'></a>\n",
    "### Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of the following code is based on the topic modelling pipeline seen on the following site:\n",
    "<br>https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/#14computemodelperplexityandcoherencescore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive : 4117\n",
      "Neutral : 35703\n",
      "Negative : 326\n"
     ]
    }
   ],
   "source": [
    "test_subset = df2['RH_Split'].values\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "pos_word_list=[]\n",
    "neu_word_list=[]\n",
    "neg_word_list=[]\n",
    "\n",
    "for value in test_subset:\n",
    "    for word in value:\n",
    "        if (sid.polarity_scores(word)['compound']) >= 0.4:\n",
    "            pos_word_list.append(word)\n",
    "        elif (sid.polarity_scores(word)['compound']) <= -0.4:\n",
    "            print\n",
    "            neg_word_list.append(word)\n",
    "        else:\n",
    "            neu_word_list.append(word)                \n",
    "\n",
    "print('Positive :', len(pos_word_list))\n",
    "print('Neutral :', len(neu_word_list))\n",
    "print('Negative :', len(neg_word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code collects (and in the later parts, remove) positive and negative words with polarity scores above 0.4 and below -0.4 respectively . This is to avoid topics found later to be based solely upon positive and negative sentiments. This approach works since we will later preemptively filter positive and negative sentiments across the three (3) destination types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop Words:  862\n"
     ]
    }
   ],
   "source": [
    "main_stop_words = ['ethiopia', 'ethiopian', 'rock', 'hewn', 'church', 'churches', 'park', 'parks', 'museum', \n",
    "                       'museums', 'omo', 'valley', 'mountain', 'mountains', 'addis', 'ababa', 'lucy', 'simien', \n",
    "                       'national', 'lalibela', 'gelada', 'haile', 'selassie', 'gondar', 'africa' , 'harar', \n",
    "                       'cathedral', 'cathedrals', 'place', 'visit', 'girmay', \n",
    "                       '\\n', '‘s']\n",
    "positive_stop_words = list(set(pos_word_list))\n",
    "negative_stop_words = list(set(neg_word_list))\n",
    "total_stop_words = main_stop_words + positive_stop_words + negative_stop_words\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "stop_words.extend(total_stop_words)\n",
    "print('Stop Words: ', len(stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code initializes the Ethiopia stop words which are mostly composed of Named Entities that we do not want to show up in our topic key words since\n",
    "they provide little value in our topic modelling analysis. These words along with the positive and negative stop words make up the total stop words to be used in the topic modelling pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sorry no - read the Bradt Guide']\n"
     ]
    }
   ],
   "source": [
    "# Convert to list\n",
    "# data = df2[df2['Destination Type'] == 'Landmarks'][df2['TextBlob Polarity Head'] > 0]['Review Head'].values.tolist() # uncomment if needed\n",
    "# data = df2[df2['Destination Type'] == 'Landmarks'][df2['TextBlob Polarity Head'] < 0]['Review Head'].values.tolist() # uncomment if needed\n",
    "# data = df2[df2['Destination Type'] == 'Nature/Parks'][df2['TextBlob Polarity Head'] > 0]['Review Head'].values.tolist() # uncomment if needed\n",
    "# data = df2[df2['Destination Type'] == 'Nature/Parks'][df2['TextBlob Polarity Head'] < 0]['Review Head'].values.tolist() # uncomment if needed\n",
    "# data = df2[df2['Destination Type'] == 'Museums'][df2['TextBlob Polarity Head'] > 0]['Review Head'].values.tolist() # uncomment if needed\n",
    "data = df2[df2['Destination Type'] == 'Museums'][df2['TextBlob Polarity Head'] < 0]['Review Head'].values.tolist()\n",
    "\n",
    "# Remove emails\n",
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline in this notebook can make use of the following six (6) LDA models:\n",
    "<li>Landmarks, Positive Sentiments</li>\n",
    "<li>Landmarks, Negative Sentiments</li>\n",
    "<li>Nature/Parks, Positive Sentiments</li>\n",
    "<li>Nature/Parks, Negative Sentiments</li>\n",
    "<li>Museums, Positive Sentiments</li>\n",
    "<li>Museums, Negative Sentiments</li>\n",
    "<br> For this notebook, the LDA model to be used will concern the Negative Sentiments toward Museums. You are free to uncomment the data-to-list conversion code accordingly above for the other LDA models. Text from Review Head is used in this case as it is the best performer (only being slightly better than Review Body Sentence 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['sorry', 'no', 'read', 'the', 'bradt', 'guide']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc = True))  # deacc = True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting sentences to words while removing punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sorry', 'no', 'read', 'the', 'bradt', 'guide']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count = 5, threshold = 100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold = 100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building bigram and trigram models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining functions for the removal of stop words, bigram/trigram implementation, and lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['read']]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm', disable = ['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags = ['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"en_core_web_sm\" model of the spaCy package may need to be installed via the terminal. If that is not possible, other english models such as \"en\" should also suffice. spaCy english models - https://spacy.io/models/en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the Dictionary and Corpus to be used for the LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('read', 1)]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model (initial testing with number of topics = 10)\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the LDA Model via gensim with 10 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.084*\"go\" + 0.071*\"worth\" + 0.067*\"bit\" + 0.059*\"ancestor\" + 0.055*\"give\" '\n",
      "  '+ 0.044*\"way\" + 0.027*\"eye\" + 0.027*\"insightful\" + 0.023*\"curate\" + '\n",
      "  '0.017*\"confusing\"'),\n",
      " (1,\n",
      "  '0.146*\"little\" + 0.029*\"closed\" + 0.029*\"lonely\" + 0.015*\"remembrance\" + '\n",
      "  '0.015*\"deserve\" + 0.015*\"attention\" + 0.015*\"tale\" + 0.015*\"rate\" + '\n",
      "  '0.015*\"underwhelme\" + 0.015*\"thing\"'),\n",
      " (2,\n",
      "  '0.155*\"see\" + 0.123*\"much\" + 0.100*\"history\" + 0.050*\"learn\" + '\n",
      "  '0.050*\"information\" + 0.042*\"else\" + 0.026*\"historical\" + 0.021*\"tough\" + '\n",
      "  '0.021*\"emotionally\" + 0.021*\"heavy\"'),\n",
      " (3,\n",
      "  '0.107*\"history\" + 0.087*\"dark\" + 0.074*\"informative\" + 0.047*\"chapter\" + '\n",
      "  '0.047*\"gem\" + 0.047*\"recent\" + 0.039*\"important\" + 0.032*\"presentation\" + '\n",
      "  '0.021*\"appropriate\" + 0.021*\"uncensored\"'),\n",
      " (4,\n",
      "  '0.075*\"hide\" + 0.059*\"different\" + 0.045*\"close\" + 0.034*\"still\" + '\n",
      "  '0.029*\"visit\" + 0.029*\"hour\" + 0.029*\"somewhat\" + 0.029*\"forget\" + '\n",
      "  '0.025*\"reality\" + 0.018*\"story\"'),\n",
      " (5,\n",
      "  '0.189*\"history\" + 0.062*\"reminder\" + 0.050*\"hard\" + 0.043*\"rather\" + '\n",
      "  '0.041*\"average\" + 0.039*\"small\" + 0.026*\"limit\" + 0.026*\"man\" + '\n",
      "  '0.018*\"regime\" + 0.016*\"information\"'),\n",
      " (6,\n",
      "  '0.105*\"poorly\" + 0.053*\"power\" + 0.053*\"pity\" + 0.053*\"outage\" + '\n",
      "  '0.032*\"maintain\" + 0.020*\"organize\" + 0.020*\"selam\" + 0.020*\"light\" + '\n",
      "  '0.020*\"well\" + 0.020*\"artefact\"'),\n",
      " (7,\n",
      "  '0.131*\"small\" + 0.078*\"past\" + 0.057*\"guide\" + 0.049*\"understand\" + '\n",
      "  '0.033*\"view\" + 0.033*\"old\" + 0.025*\"personal\" + 0.025*\"sure\" + 0.025*\"make\" '\n",
      "  '+ 0.025*\"informativ\"'),\n",
      " (8,\n",
      "  '0.097*\"time\" + 0.066*\"era\" + 0.054*\"difficult\" + 0.046*\"human\" + '\n",
      "  '0.044*\"see\" + 0.035*\"rule\" + 0.021*\"never\" + 0.021*\"display\" + '\n",
      "  '0.013*\"gruesome\" + 0.013*\"explicit\"'),\n",
      " (9,\n",
      "  '0.066*\"chill\" + 0.031*\"know\" + 0.023*\"ethiopia\" + 0.023*\"immersion\" + '\n",
      "  '0.023*\"moment\" + 0.023*\"expect\" + 0.017*\"home\" + 0.017*\"child\" + '\n",
      "  '0.017*\"overcrowded\" + 0.017*\"display\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the key words in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the key words that make up the 10 acquired topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -6.625645760659661\n",
      "\n",
      "Coherence Score:  0.5865694197868939\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the Perplexity (better if lower) and Coherence Score (range - 0 to 1, better if higher) of the LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "os.environ.update({'MALLET_HOME':r'C:/Users/HP/mallet-2.0.8/'})\n",
    "mallet_path = r'C:\\Users\\HP\\mallet-2.0.8\\bin\\mallet' # update this path\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=10, id2word=id2word, random_seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code implements the LDA Mallet Model of gensim which is generally seen as a better version of the raw LDA Model (more often shows better topics in terms of the coherence score metric and subjective identifiability)\n",
    "<br>\n",
    "<br>For this code, a zip file will need to be downloaded from the link given (http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip). the zip file in conjunction with the gensim package will enable the LDA Mallet Topic Model. The \"mallet_path\" indicates the location of the file in your local PC so adjust this accordingly with your corresponding file location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  [('history', 0.43333333333333335),\n",
      "   ('difficult', 0.1),\n",
      "   ('happen', 0.03333333333333333),\n",
      "   ('derg', 0.03333333333333333),\n",
      "   ('cover', 0.03333333333333333),\n",
      "   ('secret', 0.03333333333333333),\n",
      "   ('eye', 0.03333333333333333),\n",
      "   ('visual', 0.03333333333333333),\n",
      "   ('school', 0.03333333333333333),\n",
      "   ('tale', 0.03333333333333333)]),\n",
      " (1,\n",
      "  [('history', 0.21875),\n",
      "   ('worth', 0.15625),\n",
      "   ('presentation', 0.09375),\n",
      "   ('tough', 0.0625),\n",
      "   ('closed', 0.0625),\n",
      "   ('surprisingly', 0.03125),\n",
      "   ('unknown', 0.03125),\n",
      "   ('gruesome', 0.03125),\n",
      "   ('human', 0.03125),\n",
      "   ('reflect', 0.03125)]),\n",
      " (2,\n",
      "  [('information', 0.17391304347826086),\n",
      "   ('informative', 0.15217391304347827),\n",
      "   ('learn', 0.13043478260869565),\n",
      "   ('chill', 0.08695652173913043),\n",
      "   ('middle', 0.021739130434782608),\n",
      "   ('chilling', 0.021739130434782608),\n",
      "   ('history', 0.021739130434782608),\n",
      "   ('communist', 0.021739130434782608),\n",
      "   ('building', 0.021739130434782608),\n",
      "   ('education', 0.021739130434782608)]),\n",
      " (3,\n",
      "  [('small', 0.3333333333333333),\n",
      "   ('gem', 0.0625),\n",
      "   ('time', 0.0625),\n",
      "   ('display', 0.0625),\n",
      "   ('period', 0.041666666666666664),\n",
      "   ('view', 0.041666666666666664),\n",
      "   ('site', 0.020833333333333332),\n",
      "   ('present', 0.020833333333333332),\n",
      "   ('move', 0.020833333333333332),\n",
      "   ('pity', 0.020833333333333332)]),\n",
      " (4,\n",
      "  [('poorly', 0.14285714285714285),\n",
      "   ('past', 0.12244897959183673),\n",
      "   ('lonely', 0.04081632653061224),\n",
      "   ('shape', 0.04081632653061224),\n",
      "   ('depressing', 0.04081632653061224),\n",
      "   ('experience', 0.04081632653061224),\n",
      "   ('unsettle', 0.02040816326530612),\n",
      "   ('exhibition', 0.02040816326530612),\n",
      "   ('historic', 0.02040816326530612),\n",
      "   ('lie', 0.02040816326530612)]),\n",
      " (5,\n",
      "  [('important', 0.1111111111111111),\n",
      "   ('chapter', 0.08333333333333333),\n",
      "   ('average', 0.08333333333333333),\n",
      "   ('hide', 0.05555555555555555),\n",
      "   ('guide', 0.05555555555555555),\n",
      "   ('historical', 0.05555555555555555),\n",
      "   ('highlight', 0.027777777777777776),\n",
      "   ('photo', 0.027777777777777776),\n",
      "   ('dusty', 0.027777777777777776),\n",
      "   ('curious', 0.027777777777777776)]),\n",
      " (6,\n",
      "  [('reminder', 0.17142857142857143),\n",
      "   ('recent', 0.08571428571428572),\n",
      "   ('regime', 0.05714285714285714),\n",
      "   ('forget', 0.05714285714285714),\n",
      "   ('hit', 0.02857142857142857),\n",
      "   ('electricity', 0.02857142857142857),\n",
      "   ('ancestor', 0.02857142857142857),\n",
      "   ('access', 0.02857142857142857),\n",
      "   ('renovation', 0.02857142857142857),\n",
      "   ('city', 0.02857142857142857)]),\n",
      " (7,\n",
      "  [('hard', 0.16666666666666666),\n",
      "   ('time', 0.1111111111111111),\n",
      "   ('topic', 0.05555555555555555),\n",
      "   ('small', 0.05555555555555555),\n",
      "   ('open', 0.027777777777777776),\n",
      "   ('selam', 0.027777777777777776),\n",
      "   ('run', 0.027777777777777776),\n",
      "   ('country', 0.027777777777777776),\n",
      "   ('rimbaud', 0.027777777777777776),\n",
      "   ('immersion', 0.027777777777777776)]),\n",
      " (8,\n",
      "  [('dark', 0.23255813953488372),\n",
      "   ('bit', 0.11627906976744186),\n",
      "   ('era', 0.06976744186046512),\n",
      "   ('nonetheless', 0.023255813953488372),\n",
      "   ('big', 0.023255813953488372),\n",
      "   ('mistake', 0.023255813953488372),\n",
      "   ('window', 0.023255813953488372),\n",
      "   ('feel', 0.023255813953488372),\n",
      "   ('artefact', 0.023255813953488372),\n",
      "   ('prepare', 0.023255813953488372)]),\n",
      " (9,\n",
      "  [('history', 0.275),\n",
      "   ('close', 0.075),\n",
      "   ('reality', 0.05),\n",
      "   ('insightful', 0.05),\n",
      "   ('understand', 0.05),\n",
      "   ('terrify', 0.025),\n",
      "   ('lot', 0.025),\n",
      "   ('hearte', 0.025),\n",
      "   ('random', 0.025),\n",
      "   ('attention', 0.025)])]\n",
      "\n",
      "Coherence Score:  0.8048973809433131\n"
     ]
    }
   ],
   "source": [
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the LDA Mallet Model for 10 topics and getting the Coherence Score (higher than raw model - 0.8049 vs. 0.5866)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start, step):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        print(num_topics)\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word,\n",
    "                                                random_seed=1)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "start1 = 2 \n",
    "limit1 = 11\n",
    "step1 = 1\n",
    "\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=start1, limit=limit1, step=step1)\n",
    "\n",
    "x = range(start1, limit1, step1)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code tests for the Coherence Score metrics for LDA Mallet models with number of topics ranging from two (2) to ten (10) with a corresponding visualization. This should run relatively slower compared to other code snippets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.7754\n",
      "Num Topics = 3  has Coherence Value of 0.7736\n",
      "Num Topics = 4  has Coherence Value of 0.8153\n",
      "Num Topics = 5  has Coherence Value of 0.7928\n",
      "Num Topics = 6  has Coherence Value of 0.798\n",
      "Num Topics = 7  has Coherence Value of 0.8064\n",
      "Num Topics = 8  has Coherence Value of 0.8198\n",
      "Num Topics = 9  has Coherence Value of 0.8049\n",
      "Num Topics = 10  has Coherence Value of 0.8049\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Coherence Scores of the nine (9) LDA Models are also displayed above. In this LDA Model case, 8 topics are optimal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.184*\"informative\" + 0.158*\"past\" + 0.105*\"era\" + 0.079*\"time\" + '\n",
      "  '0.079*\"gem\" + 0.053*\"view\" + 0.026*\"tale\" + 0.026*\"derg\" + 0.026*\"cover\" + '\n",
      "  '0.026*\"raw\"'),\n",
      " (1,\n",
      "  '0.111*\"hard\" + 0.089*\"important\" + 0.067*\"presentation\" + 0.044*\"tough\" + '\n",
      "  '0.044*\"depressing\" + 0.044*\"building\" + 0.044*\"shape\" + 0.044*\"period\" + '\n",
      "  '0.044*\"small\" + 0.022*\"lighting\"'),\n",
      " (2,\n",
      "  '0.115*\"reminder\" + 0.096*\"bit\" + 0.077*\"chill\" + 0.058*\"display\" + '\n",
      "  '0.038*\"lonely\" + 0.019*\"historical\" + 0.019*\"move\" + 0.019*\"organize\" + '\n",
      "  '0.019*\"real\" + 0.019*\"chilling\"'),\n",
      " (3,\n",
      "  '0.169*\"dark\" + 0.051*\"average\" + 0.051*\"recent\" + 0.051*\"difficult\" + '\n",
      "  '0.034*\"guide\" + 0.034*\"curate\" + 0.017*\"monument\" + 0.017*\"preserve\" + '\n",
      "  '0.017*\"ministerial\" + 0.017*\"expo\"'),\n",
      " (4,\n",
      "  '0.320*\"small\" + 0.080*\"time\" + 0.040*\"regime\" + 0.040*\"hide\" + '\n",
      "  '0.040*\"forget\" + 0.020*\"ancestor\" + 0.020*\"testament\" + 0.020*\"evidence\" + '\n",
      "  '0.020*\"intense\" + 0.020*\"background\"'),\n",
      " (5,\n",
      "  '0.564*\"history\" + 0.091*\"worth\" + 0.036*\"topic\" + 0.018*\"hidden\" + '\n",
      "  '0.018*\"bone\" + 0.018*\"city\" + 0.018*\"access\" + 0.018*\"electricity\" + '\n",
      "  '0.018*\"hit\" + 0.018*\"implementation\"'),\n",
      " (6,\n",
      "  '0.143*\"poorly\" + 0.122*\"learn\" + 0.041*\"closed\" + 0.020*\"selam\" + '\n",
      "  '0.020*\"nonetheless\" + 0.020*\"rimbaud\" + 0.020*\"compelling\" + '\n",
      "  '0.020*\"exhibition\" + 0.020*\"window\" + 0.020*\"visit\"'),\n",
      " (7,\n",
      "  '0.170*\"information\" + 0.064*\"close\" + 0.064*\"chapter\" + 0.043*\"understand\" '\n",
      "  '+ 0.043*\"reality\" + 0.021*\"insightful\" + 0.021*\"random\" + 0.021*\"review\" + '\n",
      "  '0.021*\"bone\" + 0.021*\"hearte\"')]\n"
     ]
    }
   ],
   "source": [
    "optimal_model = model_list[6] # Number of Topics = 8\n",
    "\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the key words that make up the eight (8) acquired topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el863615215164526242179560274\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el863615215164526242179560274_data = {\"mdsDat\": {\"x\": [-0.18739762548377092, -0.11269773866565715, -0.21901444407209436, 0.23276397003109486, 0.08299683398947089, -0.02060921914805698, -0.09581167502223048, 0.3197698983712439], \"y\": [0.013531326570239087, -0.14916717890130307, 0.10868737919650413, 0.2385981706984019, -0.20755795244775643, -0.23862842224780448, 0.26155413448114523, -0.027017457349426555], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [12.625863647382502, 12.567699316981809, 12.557352901288027, 12.503032837365124, 12.488674345303027, 12.476454476062731, 12.402060063451755, 12.378862412165029]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\"], \"Freq\": [36.0, 22.0, 11.0, 10.0, 10.0, 9.0, 8.0, 7.0, 7.0, 9.0, 6.0, 7.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 3.1457660273986905, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 3.1457660273986905, 3.1457660273986905, 10.485886757995633, 1.0485886757995635, 2.097177351599127, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 2.097177351599127, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 5.921319870501043, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 4.737055896400835, 7.105583844601252, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 3.552791922300626, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 2.3685279482004176, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1187459857511148, 1.1187459857511148, 5.593729928755574, 1.1187459857511148, 1.1187459857511148, 1.1187459857511148, 1.1187459857511148, 1.1187459857511148, 1.1187459857511148, 2.2374919715022297, 1.1187459857511148, 1.1187459857511148, 1.1187459857511148, 1.1187459857511148, 1.1187459857511148, 34.681125558284556, 1.1187459857511148, 1.1187459857511148, 1.1187459857511148, 1.1187459857511148, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 2.450594436123564, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 2.450594436123564, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 19.604755488988513, 2.450594436123564, 1.225297218061782, 4.901188872247128, 0.0, 0.0, 0.0, 0.0, 0.0, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 7.493204607181815, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 2.4977348690606047, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 8.742072041712117, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 3.9022102297472783, 3.9022102297472783, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 10.405893945992743, 1.3007367432490928, 2.6014734864981857, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 2.6014734864981857, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 2.700893080485048, 1.350446540242524, 4.051339620727572, 1.350446540242524, 2.700893080485048, 2.700893080485048, 5.401786160970096, 2.700893080485048, 1.350446540242524, 2.700893080485048, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 6.75223270121262, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 2.700893080485048, 1.350446540242524, 3.1924434641899277, 1.5962217320949639, 1.5962217320949639, 1.5962217320949639, 1.5962217320949639, 1.5962217320949639, 1.5962217320949639, 1.5962217320949639, 1.5962217320949639, 1.5962217320949639, 4.788665196284891, 11.173552124664747, 6.3848869283798555, 9.577330392569783, 1.5962217320949639, 1.5962217320949639, 1.5962217320949639, 1.5962217320949639, 4.788665196284891, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"Term\": [\"history\", \"small\", \"informative\", \"dark\", \"information\", \"past\", \"poorly\", \"learn\", \"reminder\", \"time\", \"era\", \"hard\", \"bit\", \"worth\", \"important\", \"gem\", \"chill\", \"presentation\", \"close\", \"chapter\", \"display\", \"view\", \"difficult\", \"average\", \"recent\", \"period\", \"building\", \"depressing\", \"shape\", \"tough\", \"man\", \"historic\", \"heavy\", \"lie\", \"picture\", \"range\", \"average\", \"site\", \"wall\", \"preserve\", \"monument\", \"difficult\", \"recent\", \"dark\", \"insight\", \"curate\", \"overcrowded\", \"archeologic\", \"captivate\", \"ministerial\", \"day\", \"moment\", \"unsettle\", \"sober\", \"handle\", \"fragmentary\", \"overrated\", \"personal\", \"busy\", \"pass\", \"expo\", \"absolutely\", \"modern\", \"guide\", \"dusty\", \"historical\", \"maintain\", \"hard\", \"hour\", \"big\", \"pity\", \"move\", \"interste\", \"bit\", \"child\", \"home\", \"island\", \"chill\", \"reminder\", \"harrowing\", \"money\", \"people\", \"miss\", \"real\", \"diverse\", \"essential\", \"display\", \"chilling\", \"reveal\", \"thing\", \"collection\", \"organize\", \"due\", \"lonely\", \"previously\", \"limited\", \"hour\", \"historical\", \"country\", \"exhibition\", \"present\", \"lot\", \"experience\", \"stuff\", \"visual\", \"open\", \"worth\", \"access\", \"hit\", \"terrify\", \"implementation\", \"potential\", \"city\", \"topic\", \"tiny\", \"side\", \"explicit\", \"hidden\", \"electricity\", \"history\", \"rest\", \"dusty\", \"country\", \"bone\", \"read\", \"display\", \"poorly\", \"interste\", \"presentation\", \"stuff\", \"visited\", \"captivate\", \"keep\", \"much\", \"exhibition\", \"painting\", \"site\", \"time\", \"derg\", \"raw\", \"gem\", \"wall\", \"essential\", \"testament\", \"move\", \"uncensored\", \"ethiopia\", \"educational\", \"intense\", \"testament\", \"painting\", \"background\", \"photo\", \"highlight\", \"everyday\", \"forget\", \"repeat\", \"rule\", \"confusing\", \"remembrance\", \"disorganized\", \"renovation\", \"rate\", \"regime\", \"evidence\", \"underwhelme\", \"green\", \"curious\", \"typical\", \"emotional\", \"small\", \"hide\", \"ancestor\", \"time\", \"read\", \"chilling\", \"uncomfortably\", \"miss\", \"raw\", \"limit\", \"selam\", \"group\", \"learn\", \"window\", \"watch\", \"govern\", \"upgrade\", \"negative\", \"mistake\", \"poignant\", \"expect\", \"immersion\", \"distant\", \"story\", \"minimal\", \"exceed\", \"closed\", \"informativ\", \"tribe\", \"area\", \"power\", \"nonetheless\", \"compelling\", \"rimbaud\", \"make\", \"expensive\", \"feel\", \"depress\", \"derge\", \"poorly\", \"planet\", \"run\", \"exhibit\", \"exhibition\", \"insightful\", \"visit\", \"close\", \"chapter\", \"careful\", \"deserve\", \"hearte\", \"information\", \"info\", \"reality\", \"package\", \"relative\", \"insane\", \"overview\", \"attention\", \"visited\", \"random\", \"source\", \"light\", \"emotionally\", \"narration\", \"wukro\", \"prepare\", \"intentione\", \"artefact\", \"review\", \"understand\", \"big\", \"bone\", \"lot\", \"eye\", \"human\", \"insightful\", \"raw\", \"hide\", \"guide\", \"tough\", \"gruesome\", \"presentation\", \"ethnic\", \"shape\", \"building\", \"important\", \"period\", \"outage\", \"depressing\", \"unknown\", \"uncomfortably\", \"read\", \"education\", \"middle\", \"dilapidate\", \"spot\", \"reflect\", \"communist\", \"lighting\", \"surprisingly\", \"rain\", \"hard\", \"maintain\", \"experience\", \"give\", \"present\", \"visit\", \"small\", \"history\", \"view\", \"tour\", \"school\", \"tale\", \"grace\", \"happen\", \"cover\", \"secret\", \"derg\", \"skip\", \"gem\", \"informative\", \"era\", \"past\", \"bore\", \"stuff\", \"exhibit\", \"raw\", \"time\", \"read\", \"display\", \"poorly\", \"interste\", \"presentation\", \"visited\", \"captivate\", \"keep\", \"much\", \"probably\", \"see\", \"diverse\", \"wall\", \"dusty\", \"painting\", \"essential\", \"testament\", \"chapter\", \"site\", \"implementation\", \"potential\", \"average\"], \"Total\": [36.0, 22.0, 11.0, 10.0, 10.0, 9.0, 8.0, 7.0, 7.0, 9.0, 6.0, 7.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 3.1457660273986905, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 3.1457660273986905, 3.1457660273986905, 10.485886757995633, 1.0485886757995635, 2.097177351599127, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 1.0485886757995635, 3.39791409484822, 2.1673346615506786, 2.2328526498997725, 2.399035216042088, 7.800821377012183, 2.2328526498997725, 2.3493254190486565, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 5.921319870501043, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 4.737055896400835, 7.105583844601252, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 3.552791922300626, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 1.1842639741002088, 2.3685279482004176, 1.1842639741002088, 1.1842639741002088, 2.2328526498997725, 2.2328526498997725, 2.3030099598513236, 2.433131408630511, 2.534710514342733, 2.4850007173493016, 2.534710514342733, 2.7804857061951727, 1.1187459857511148, 1.1187459857511148, 5.593729928755574, 1.1187459857511148, 1.1187459857511148, 1.1187459857511148, 1.1187459857511148, 1.1187459857511148, 1.1187459857511148, 2.2374919715022297, 1.1187459857511148, 1.1187459857511148, 1.1187459857511148, 1.1187459857511148, 1.1187459857511148, 36.03157209852708, 2.1673346615506786, 2.1673346615506786, 2.3030099598513236, 2.4194827290002077, 1.350446540242524, 3.552791922300626, 8.742072041712117, 1.1842639741002088, 4.051339620727572, 2.7804857061951727, 1.3007367432490928, 1.0485886757995635, 0.0, 0.0, 2.433131408630511, 1.225297218061782, 1.0485886757995635, 9.68985406853202, 1.5962217320949639, 2.8969584753440567, 4.788665196284891, 1.0485886757995635, 1.1842639741002088, 1.225297218061782, 1.1842639741002088, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 2.450594436123564, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 2.450594436123564, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 1.225297218061782, 22.30564856947356, 3.7513311793726567, 2.2738858938613458, 9.68985406853202, 1.350446540242524, 1.1842639741002088, 1.350446540242524, 1.1842639741002088, 2.8969584753440567, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 7.493204607181815, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 2.4977348690606047, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 1.2488674345303024, 8.742072041712117, 1.2488674345303024, 1.2488674345303024, 2.8450891666252662, 2.433131408630511, 2.549604177779395, 2.5993139747728264, 3.9022102297472783, 3.9022102297472783, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 10.405893945992743, 1.3007367432490928, 2.6014734864981857, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 1.3007367432490928, 2.6014734864981857, 2.3493254190486565, 2.4194827290002077, 2.4850007173493016, 2.4850007173493016, 2.4850007173493016, 2.549604177779395, 2.8969584753440567, 3.7513311793726567, 3.39791409484822, 2.700893080485048, 1.350446540242524, 4.051339620727572, 1.350446540242524, 2.700893080485048, 2.700893080485048, 5.401786160970096, 2.700893080485048, 1.350446540242524, 2.700893080485048, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 1.350446540242524, 7.800821377012183, 2.399035216042088, 2.534710514342733, 2.534710514342733, 2.534710514342733, 2.5993139747728264, 22.30564856947356, 36.03157209852708, 3.1924434641899277, 1.5962217320949639, 1.5962217320949639, 1.5962217320949639, 1.5962217320949639, 1.5962217320949639, 1.5962217320949639, 1.5962217320949639, 1.5962217320949639, 1.5962217320949639, 4.788665196284891, 11.173552124664747, 6.3848869283798555, 9.577330392569783, 1.5962217320949639, 2.7804857061951727, 2.8450891666252662, 2.8969584753440567, 9.68985406853202, 1.350446540242524, 3.552791922300626, 8.742072041712117, 1.1842639741002088, 4.051339620727572, 1.3007367432490928, 1.0485886757995635, 0.0, 0.0, 0.0, 0.0, 1.1842639741002088, 1.0485886757995635, 2.1673346615506786, 1.225297218061782, 1.1842639741002088, 1.225297218061782, 3.9022102297472783, 1.0485886757995635, 1.1187459857511148, 1.1187459857511148, 3.1457660273986905], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 2.0694, 1.5869, 1.3434, 1.3136, 1.2418, 0.0626, 1.3136, 1.2627, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 2.074, 1.4399, 1.4399, 1.4089, 1.354, 1.3131, 1.3329, 1.3131, 1.2205, 2.0749, 2.0749, 2.0749, 2.0749, 2.0749, 2.0749, 2.0749, 2.0749, 2.0749, 2.0749, 2.0749, 2.0749, 2.0749, 2.0749, 2.0749, 2.0367, 1.4136, 1.4136, 1.3529, 1.3035, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, NaN, NaN, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 2.0792, 1.9501, 1.6534, 1.4609, 1.3976, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 2.0803, 1.257, 1.4134, 1.3666, 1.3473, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 2.0813, 1.4901, 1.4607, 1.434, 1.434, 1.434, 1.4083, 1.2806, 1.0221, 1.1211, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 2.0873, 1.943, 1.5127, 1.4577, 1.4577, 1.4577, 1.4325, -0.0239, -1.1967, 2.0892, 2.0892, 2.0892, 2.0892, 2.0892, 2.0892, 2.0892, 2.0892, 2.0892, 2.0892, 2.0892, 2.0892, 2.0892, 2.0892, 2.0892, 1.5342, 1.5112, 1.4932, 1.3844, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, NaN, NaN, NaN, NaN, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.0775, -4.0775, -4.0775, -4.0775, -4.0775, -4.0775, -2.9789, -4.0775, -4.0775, -4.0775, -4.0775, -2.9789, -2.9789, -1.775, -4.0775, -3.3844, -4.0775, -4.0775, -4.0775, -4.0775, -4.0775, -4.0775, -4.0775, -4.0775, -4.0775, -4.0775, -4.0775, -4.0775, -4.0775, -4.0775, -4.0775, -4.0775, -4.0775, -3.3844, -4.0775, -4.0775, -4.0775, -4.0775, -4.0775, -4.0775, -3.9512, -3.9512, -3.9512, -2.3418, -3.9512, -3.9512, -3.9512, -2.5649, -2.1595, -3.9512, -3.9512, -3.9512, -3.9512, -3.9512, -3.9512, -3.9512, -2.8526, -3.9512, -3.9512, -3.9512, -3.9512, -3.9512, -3.9512, -3.2581, -3.9512, -3.9512, -3.9512, -3.9512, -3.9512, -3.9512, -3.9512, -3.9512, -3.9512, -3.9512, -4.0073, -4.0073, -2.3979, -4.0073, -4.0073, -4.0073, -4.0073, -4.0073, -4.0073, -3.3142, -4.0073, -4.0073, -4.0073, -4.0073, -4.0073, -0.5733, -4.0073, -4.0073, -4.0073, -4.0073, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -3.912, -3.912, -3.912, -3.912, -3.912, -3.912, -3.912, -3.912, -3.912, -3.912, -3.2189, -3.912, -3.912, -3.912, -3.912, -3.912, -3.912, -3.912, -3.2189, -3.912, -3.912, -3.912, -3.912, -3.912, -3.912, -1.1394, -3.2189, -3.912, -2.5257, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -3.8918, -3.8918, -3.8918, -2.1001, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -3.1987, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -1.9459, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -3.8918, -2.7515, -2.7515, -3.8501, -3.8501, -3.8501, -1.7707, -3.8501, -3.157, -3.8501, -3.8501, -3.8501, -3.8501, -3.8501, -3.8501, -3.8501, -3.8501, -3.8501, -3.8501, -3.8501, -3.8501, -3.8501, -3.8501, -3.8501, -3.8501, -3.157, -3.8501, -3.8501, -3.8501, -3.8501, -3.8501, -3.8501, -3.8501, -3.8501, -3.8501, -3.1135, -3.8067, -2.7081, -3.8067, -3.1135, -3.1135, -2.4204, -3.1135, -3.8067, -3.1135, -3.8067, -3.8067, -3.8067, -3.8067, -3.8067, -3.8067, -3.8067, -3.8067, -3.8067, -3.8067, -3.8067, -3.8067, -2.1972, -3.8067, -3.8067, -3.8067, -3.8067, -3.8067, -3.1135, -3.8067, -2.9444, -3.6376, -3.6376, -3.6376, -3.6376, -3.6376, -3.6376, -3.6376, -3.6376, -3.6376, -2.539, -1.6917, -2.2513, -1.8458, -3.6376, -3.6376, -3.6376, -3.6376, -2.539, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity, -Infinity]}, \"token.table\": {\"Topic\": [1, 3, 1, 4, 1, 5, 6, 6, 1, 4, 1, 6, 2, 3, 6, 8, 7, 1, 1, 6, 6, 2, 2, 2, 3, 6, 5, 2, 7, 5, 4, 2, 3, 8, 1, 4, 1, 1, 5, 7, 8, 5, 6, 1, 7, 4, 2, 5, 2, 2, 1, 3, 7, 4, 3, 4, 6, 8, 2, 4, 7, 4, 4, 5, 5, 8, 2, 5, 5, 5, 2, 7, 3, 1, 2, 6, 5, 4, 1, 8, 2, 7, 5, 8, 4, 5, 7, 1, 6, 1, 8, 1, 7, 2, 6, 1, 3, 4, 6, 4, 1, 1, 2, 3, 7, 3, 2, 1, 2, 2, 6, 5, 3, 7, 6, 6, 5, 8, 6, 1, 5, 6, 4, 6, 2, 2, 5, 1, 6, 7, 5, 2, 2, 2, 6, 1, 7, 5, 1, 7, 5, 1, 2, 5, 1, 1, 2, 1, 2, 6, 5, 5, 3, 2, 7, 1, 1, 6, 6, 4, 1, 8, 2, 7, 1, 4, 1, 2, 5, 5, 5, 3, 5, 6, 2, 7, 7, 1, 2, 7, 6, 1, 4, 6, 8, 7, 2, 6, 1, 7, 4, 6, 4, 2, 4, 4, 1, 3, 2, 6, 5, 4, 5, 8, 8, 5, 7, 3, 1, 8, 4, 7, 1, 6, 7, 5, 2, 8, 7, 8, 3, 4, 2, 4, 8, 3, 3, 7, 8, 5, 4, 4, 7, 6, 4, 7, 1, 5, 8, 5, 7, 6, 3, 1, 5, 5, 3, 6], \"Freq\": [0.9536627879730687, 0.8938579559046284, 0.43977580524142906, 0.43977580524142906, 0.9536627879730687, 0.8007254992409173, 0.7687950733997976, 0.7687950733997976, 0.9536627879730687, 0.8161285158076462, 0.42565410133984044, 0.42565410133984044, 1.013287599930368, 0.41331148514262206, 0.41331148514262206, 1.252958758665124, 1.1107437098032906, 0.9536627879730687, 0.9536627879730687, 0.7687950733997976, 1.0250600978663968, 0.8444063332753067, 1.0555079165941332, 0.8444063332753067, 0.8938579559046284, 1.0250600978663968, 0.8007254992409173, 0.8444063332753067, 0.740495806535527, 0.8007254992409173, 0.8161285158076462, 0.4342143618278392, 0.4342143618278392, 1.252958758665124, 0.9536627879730687, 0.8161285158076462, 0.9536627879730689, 0.9536627879730687, 0.8007254992409173, 1.1107437098032906, 1.252958758665124, 0.8007254992409173, 0.7687950733997976, 0.9536627879730687, 0.740495806535527, 0.8161285158076462, 1.1258751110337422, 0.8007254992409173, 0.8444063332753067, 0.8444063332753067, 0.461396210626984, 0.461396210626984, 0.740495806535527, 0.8161285158076462, 0.8938579559046284, 0.8161285158076462, 0.7687950733997976, 0.9397190689988429, 0.8444063332753067, 0.8161285158076462, 0.740495806535527, 0.8161285158076462, 0.8161285158076462, 0.8007254992409173, 0.3514828328513025, 0.702965665702605, 0.4109930094416275, 0.4109930094416275, 0.8007254992409173, 0.8007254992409173, 0.3945223702436515, 0.3945223702436515, 0.8938579559046284, 0.9536627879730687, 0.40241437075586806, 0.40241437075586806, 0.8007254992409173, 0.8161285158076462, 0.9536627879730687, 1.0441322988876034, 0.3945223702436515, 0.3945223702436515, 0.8007254992409173, 1.252958758665124, 0.8161285158076462, 0.8007254992409173, 0.740495806535527, 0.588596398900231, 0.2942981994501155, 0.9536627879730687, 1.252958758665124, 0.12819162901830386, 0.8973414031281269, 0.8444063332753067, 0.7687950733997976, 0.9536627879730687, 0.8938579559046284, 0.533144077227131, 0.2665720386135655, 0.8161285158076462, 0.9536627879730687, 0.44785758704000805, 0.44785758704000805, 0.9713703277862459, 0.02775343793674988, 0.8938579559046284, 0.8444063332753067, 0.44785758704000805, 0.44785758704000805, 0.40241437075586806, 0.40241437075586806, 0.8007254992409173, 0.8938579559046284, 0.9256197581694089, 0.7687950733997976, 0.960993841749747, 0.8007254992409173, 0.984467596094026, 0.7687950733997976, 0.9536627879730687, 0.39221774450925184, 0.39221774450925184, 0.8161285158076462, 0.7687950733997976, 0.8444063332753067, 0.8444063332753067, 0.9341797491144035, 0.9536627879730687, 0.7687950733997976, 0.740495806535527, 0.8007254992409173, 0.8444063332753067, 0.8444063332753067, 0.40241437075586806, 0.40241437075586806, 0.416834231241421, 0.416834231241421, 0.8007254992409173, 0.9536627879730687, 0.740495806535527, 0.8007254992409173, 0.9536627879730687, 0.8444063332753067, 0.8007254992409173, 0.9536627879730687, 0.9536627879730687, 0.8444063332753067, 0.9536627879730687, 0.8444063332753067, 0.7687950733997976, 0.8007254992409173, 0.8007254992409173, 0.8938579559046284, 0.8444063332753067, 0.740495806535527, 0.9536627879730687, 0.9536627879730687, 0.7687950733997976, 0.7687950733997976, 0.8161285158076462, 0.9536627879730687, 1.0441322988876034, 0.8444063332753067, 1.1107437098032906, 0.9536627879730687, 0.8161285158076462, 0.9536627879730687, 0.8444063332753067, 0.8007254992409173, 0.8007254992409173, 1.0295042133097507, 0.8938579559046284, 0.8007254992409173, 0.7687950733997976, 0.3945223702436515, 0.3945223702436515, 0.9873277420473695, 0.9536627879730687, 0.8444063332753067, 0.740495806535527, 0.7687950733997976, 0.9536627879730687, 0.8161285158076462, 0.3451896216362698, 0.6903792432725396, 0.740495806535527, 0.8444063332753067, 1.1531926100996963, 0.9536627879730687, 0.740495806535527, 0.8161285158076462, 0.7687950733997976, 0.8161285158076462, 0.9851407221545244, 0.8161285158076462, 0.8161285158076462, 0.461396210626984, 0.461396210626984, 0.8444063332753067, 0.7687950733997976, 0.8007254992409173, 0.8161285158076462, 0.8007254992409173, 1.252958758665124, 1.252958758665124, 0.8007254992409173, 1.1107437098032906, 0.8938579559046284, 0.9536627879730687, 1.252958758665124, 0.8966338700131338, 0.13449508050197007, 0.9536627879730687, 0.7687950733997976, 0.740495806535527, 0.8007254992409173, 0.359649394266588, 0.719298788533176, 0.740495806535527, 1.252958758665124, 0.8938579559046284, 0.8161285158076462, 0.8444063332753067, 0.5160036430515081, 0.5160036430515081, 0.8938579559046284, 0.8938579559046284, 1.1107437098032906, 1.252958758665124, 0.8007254992409173, 0.8161285158076462, 0.8161285158076462, 0.740495806535527, 1.1531926100996963, 0.8161285158076462, 0.740495806535527, 0.9536627879730687, 0.8007254992409173, 0.9397190689988429, 0.3847168944211126, 0.3847168944211126, 0.7687950733997976, 0.8938579559046284, 0.9536627879730687, 0.8007254992409173, 0.8007254992409173, 1.072629547085554, 0.7687950733997976], \"Term\": [\"absolutely\", \"access\", \"ancestor\", \"ancestor\", \"archeologic\", \"area\", \"artefact\", \"attention\", \"average\", \"background\", \"big\", \"big\", \"bit\", \"bone\", \"bone\", \"bore\", \"building\", \"busy\", \"captivate\", \"careful\", \"chapter\", \"child\", \"chill\", \"chilling\", \"city\", \"close\", \"closed\", \"collection\", \"communist\", \"compelling\", \"confusing\", \"country\", \"country\", \"cover\", \"curate\", \"curious\", \"dark\", \"day\", \"depress\", \"depressing\", \"derg\", \"derge\", \"deserve\", \"difficult\", \"dilapidate\", \"disorganized\", \"display\", \"distant\", \"diverse\", \"due\", \"dusty\", \"dusty\", \"education\", \"educational\", \"electricity\", \"emotional\", \"emotionally\", \"era\", \"essential\", \"ethiopia\", \"ethnic\", \"everyday\", \"evidence\", \"exceed\", \"exhibit\", \"exhibit\", \"exhibition\", \"exhibition\", \"expect\", \"expensive\", \"experience\", \"experience\", \"explicit\", \"expo\", \"eye\", \"eye\", \"feel\", \"forget\", \"fragmentary\", \"gem\", \"give\", \"give\", \"govern\", \"grace\", \"green\", \"group\", \"gruesome\", \"guide\", \"guide\", \"handle\", \"happen\", \"hard\", \"hard\", \"harrowing\", \"hearte\", \"heavy\", \"hidden\", \"hide\", \"hide\", \"highlight\", \"historic\", \"historical\", \"historical\", \"history\", \"history\", \"hit\", \"home\", \"hour\", \"hour\", \"human\", \"human\", \"immersion\", \"implementation\", \"important\", \"info\", \"information\", \"informativ\", \"informative\", \"insane\", \"insight\", \"insightful\", \"insightful\", \"intense\", \"intentione\", \"interste\", \"island\", \"learn\", \"lie\", \"light\", \"lighting\", \"limit\", \"limited\", \"lonely\", \"lot\", \"lot\", \"maintain\", \"maintain\", \"make\", \"man\", \"middle\", \"minimal\", \"ministerial\", \"miss\", \"mistake\", \"modern\", \"moment\", \"money\", \"monument\", \"move\", \"narration\", \"negative\", \"nonetheless\", \"open\", \"organize\", \"outage\", \"overcrowded\", \"overrated\", \"overview\", \"package\", \"painting\", \"pass\", \"past\", \"people\", \"period\", \"personal\", \"photo\", \"picture\", \"pity\", \"planet\", \"poignant\", \"poorly\", \"potential\", \"power\", \"prepare\", \"present\", \"present\", \"presentation\", \"preserve\", \"previously\", \"rain\", \"random\", \"range\", \"rate\", \"raw\", \"raw\", \"read\", \"real\", \"reality\", \"recent\", \"reflect\", \"regime\", \"relative\", \"remembrance\", \"reminder\", \"renovation\", \"repeat\", \"rest\", \"rest\", \"reveal\", \"review\", \"rimbaud\", \"rule\", \"run\", \"school\", \"secret\", \"selam\", \"shape\", \"side\", \"site\", \"skip\", \"small\", \"small\", \"sober\", \"source\", \"spot\", \"story\", \"stuff\", \"stuff\", \"surprisingly\", \"tale\", \"terrify\", \"testament\", \"thing\", \"time\", \"time\", \"tiny\", \"topic\", \"tough\", \"tour\", \"tribe\", \"typical\", \"uncensored\", \"uncomfortably\", \"understand\", \"underwhelme\", \"unknown\", \"unsettle\", \"upgrade\", \"view\", \"visit\", \"visit\", \"visited\", \"visual\", \"wall\", \"watch\", \"window\", \"worth\", \"wukro\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 3, 6, 5, 7, 8, 2, 1]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el863615215164526242179560274\", ldavis_el863615215164526242179560274_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el863615215164526242179560274\", ldavis_el863615215164526242179560274_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el863615215164526242179560274\", ldavis_el863615215164526242179560274_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "3     -0.187398  0.013531       1        1  12.625864\n",
       "2     -0.112698 -0.149167       2        1  12.567699\n",
       "5     -0.219014  0.108687       3        1  12.557353\n",
       "4      0.232764  0.238598       4        1  12.503033\n",
       "6      0.082997 -0.207558       5        1  12.488674\n",
       "7     -0.020609 -0.238628       6        1  12.476454\n",
       "1     -0.095812  0.261554       7        1  12.402060\n",
       "0      0.319770 -0.027017       8        1  12.378862, topic_info=    Category       Freq            Term      Total  loglift  logprob\n",
       "28   Default  36.000000         history  36.000000  30.0000  30.0000\n",
       "44   Default  22.000000           small  22.000000  29.0000  29.0000\n",
       "63   Default  11.000000     informative  11.000000  28.0000  28.0000\n",
       "55   Default  10.000000            dark  10.000000  27.0000  27.0000\n",
       "38   Default  10.000000     information  10.000000  26.0000  26.0000\n",
       "48   Default   9.000000            past   9.000000  25.0000  25.0000\n",
       "2    Default   8.000000          poorly   8.000000  24.0000  24.0000\n",
       "23   Default   7.000000           learn   7.000000  23.0000  23.0000\n",
       "57   Default   7.000000        reminder   7.000000  22.0000  22.0000\n",
       "89   Default   9.000000            time   9.000000  21.0000  21.0000\n",
       "60   Default   6.000000             era   6.000000  20.0000  20.0000\n",
       "50   Default   7.000000            hard   7.000000  19.0000  19.0000\n",
       "12   Default   5.000000             bit   5.000000  18.0000  18.0000\n",
       "36   Default   5.000000           worth   5.000000  17.0000  17.0000\n",
       "68   Default   5.000000       important   5.000000  16.0000  16.0000\n",
       "85   Default   4.000000             gem   4.000000  15.0000  15.0000\n",
       "34   Default   4.000000           chill   4.000000  14.0000  14.0000\n",
       "4    Default   4.000000    presentation   4.000000  13.0000  13.0000\n",
       "46   Default   3.000000           close   3.000000  12.0000  12.0000\n",
       "79   Default   3.000000         chapter   3.000000  11.0000  11.0000\n",
       "1    Default   3.000000         display   3.000000  10.0000  10.0000\n",
       "215  Default   3.000000            view   3.000000   9.0000   9.0000\n",
       "59   Default   3.000000       difficult   3.000000   8.0000   8.0000\n",
       "94   Default   3.000000         average   3.000000   7.0000   7.0000\n",
       "56   Default   3.000000          recent   3.000000   6.0000   6.0000\n",
       "72   Default   2.000000          period   2.000000   5.0000   5.0000\n",
       "37   Default   2.000000        building   2.000000   4.0000   4.0000\n",
       "76   Default   2.000000      depressing   2.000000   3.0000   3.0000\n",
       "29   Default   2.000000           shape   2.000000   2.0000   2.0000\n",
       "244  Default   2.000000           tough   2.000000   1.0000   1.0000\n",
       "..       ...        ...             ...        ...      ...      ...\n",
       "63    Topic8  11.173552     informative  11.173552   2.0892  -1.6917\n",
       "60    Topic8   6.384887             era   6.384887   2.0892  -2.2513\n",
       "48    Topic8   9.577330            past   9.577330   2.0892  -1.8458\n",
       "41    Topic8   1.596222            bore   1.596222   2.0892  -3.6376\n",
       "5     Topic8   1.596222           stuff   2.780486   1.5342  -3.6376\n",
       "139   Topic8   1.596222         exhibit   2.845089   1.5112  -3.6376\n",
       "86    Topic8   1.596222             raw   2.896958   1.4932  -3.6376\n",
       "89    Topic8   4.788665            time   9.689854   1.3844  -2.5390\n",
       "0     Topic8   0.000000            read   1.350447     -inf     -inf\n",
       "1     Topic8   0.000000         display   3.552792     -inf     -inf\n",
       "2     Topic8   0.000000          poorly   8.742072     -inf     -inf\n",
       "3     Topic8   0.000000        interste   1.184264     -inf     -inf\n",
       "4     Topic8   0.000000    presentation   4.051340     -inf     -inf\n",
       "6     Topic8   0.000000         visited   1.300737     -inf     -inf\n",
       "7     Topic8   0.000000       captivate   1.048589     -inf     -inf\n",
       "8     Topic8   0.000000            keep   0.000000      NaN     -inf\n",
       "9     Topic8   0.000000            much   0.000000      NaN     -inf\n",
       "10    Topic8   0.000000        probably   0.000000      NaN     -inf\n",
       "11    Topic8   0.000000             see   0.000000      NaN     -inf\n",
       "96    Topic8   0.000000         diverse   1.184264     -inf     -inf\n",
       "84    Topic8   0.000000            wall   1.048589     -inf     -inf\n",
       "88    Topic8   0.000000           dusty   2.167335     -inf     -inf\n",
       "83    Topic8   0.000000        painting   1.225297     -inf     -inf\n",
       "81    Topic8   0.000000       essential   1.184264     -inf     -inf\n",
       "80    Topic8   0.000000       testament   1.225297     -inf     -inf\n",
       "79    Topic8   0.000000         chapter   3.902210     -inf     -inf\n",
       "90    Topic8   0.000000            site   1.048589     -inf     -inf\n",
       "91    Topic8   0.000000  implementation   1.118746     -inf     -inf\n",
       "92    Topic8   0.000000       potential   1.118746     -inf     -inf\n",
       "94    Topic8   0.000000         average   3.145766     -inf     -inf\n",
       "\n",
       "[321 rows x 6 columns], token_table=      Topic      Freq           Term\n",
       "term                                \n",
       "211       1  0.953663     absolutely\n",
       "49        3  0.893858         access\n",
       "184       1  0.439776       ancestor\n",
       "184       4  0.439776       ancestor\n",
       "138       1  0.953663    archeologic\n",
       "245       5  0.800725           area\n",
       "178       6  0.768795       artefact\n",
       "150       6  0.768795      attention\n",
       "94        1  0.953663        average\n",
       "99        4  0.816129     background\n",
       "117       1  0.425654            big\n",
       "117       6  0.425654            big\n",
       "12        2  1.013288            bit\n",
       "42        3  0.413311           bone\n",
       "42        6  0.413311           bone\n",
       "41        8  1.252959           bore\n",
       "37        7  1.110744       building\n",
       "218       1  0.953663           busy\n",
       "7         1  0.953663      captivate\n",
       "258       6  0.768795        careful\n",
       "79        6  1.025060        chapter\n",
       "15        2  0.844406          child\n",
       "34        2  1.055508          chill\n",
       "118       2  0.844406       chilling\n",
       "219       3  0.893858           city\n",
       "46        6  1.025060          close\n",
       "175       5  0.800725         closed\n",
       "160       2  0.844406     collection\n",
       "162       7  0.740496      communist\n",
       "232       5  0.800725     compelling\n",
       "...     ...       ...            ...\n",
       "227       7  0.740496   surprisingly\n",
       "153       8  1.252959           tale\n",
       "67        3  0.893858        terrify\n",
       "80        4  0.816129      testament\n",
       "216       2  0.844406          thing\n",
       "89        4  0.516004           time\n",
       "89        8  0.516004           time\n",
       "123       3  0.893858           tiny\n",
       "98        3  0.893858          topic\n",
       "244       7  1.110744          tough\n",
       "32        8  1.252959           tour\n",
       "247       5  0.800725          tribe\n",
       "238       4  0.816129        typical\n",
       "252       4  0.816129     uncensored\n",
       "74        7  0.740496  uncomfortably\n",
       "226       6  1.153193     understand\n",
       "217       4  0.816129    underwhelme\n",
       "112       7  0.740496        unknown\n",
       "163       1  0.953663       unsettle\n",
       "130       5  0.800725        upgrade\n",
       "215       8  0.939719           view\n",
       "33        5  0.384717          visit\n",
       "33        7  0.384717          visit\n",
       "6         6  0.768795        visited\n",
       "228       3  0.893858         visual\n",
       "84        1  0.953663           wall\n",
       "104       5  0.800725          watch\n",
       "62        5  0.800725         window\n",
       "36        3  1.072630          worth\n",
       "203       6  0.768795          wukro\n",
       "\n",
       "[248 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 3, 6, 5, 7, 8, 2, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert LDA Mallet to normal LDA since pyLDAvis only takes the latter for visualization\n",
    "optimal_model2 = gensim.models.wrappers.ldamallet.malletmodel2ldamodel(optimal_model)\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(optimal_model2, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyLDAvis allows visualization for topic modelling as seen from the above code. We did not decide to include this in the final presentation as there is too much data to be compressed in a slide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>hard, important, presentation, tough, depressi...</td>\n",
       "      <td>Sorry no - read the Bradt Guide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>reminder, bit, chill, display, lonely, histori...</td>\n",
       "      <td>Dusty and poorly displayed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>reminder, bit, chill, display, lonely, histori...</td>\n",
       "      <td>Intersting stuff, but poor presentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>information, close, chapter, understand, reali...</td>\n",
       "      <td>Shocking but must be visited!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>dark, average, recent, difficult, guide, curat...</td>\n",
       "      <td>Captivating and shocking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>informative, past, era, time, gem, view, tale,...</td>\n",
       "      <td>Probably a must see, but not much to keep you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1394</td>\n",
       "      <td>informative, past, era, time, gem, view, tale,...</td>\n",
       "      <td>Grace gone a bit down.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1692</td>\n",
       "      <td>reminder, bit, chill, display, lonely, histori...</td>\n",
       "      <td>Home to Lucy but overcrowded with Children and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>informative, past, era, time, gem, view, tale,...</td>\n",
       "      <td>Hardly world class</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>informative, past, era, time, gem, view, tale,...</td>\n",
       "      <td>Disappointing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0             1.0              0.1422   \n",
       "1            1             2.0              0.1394   \n",
       "2            2             2.0              0.1410   \n",
       "3            3             7.0              0.1422   \n",
       "4            4             3.0              0.1400   \n",
       "5            5             0.0              0.1250   \n",
       "6            6             0.0              0.1394   \n",
       "7            7             2.0              0.1692   \n",
       "8            8             0.0              0.1250   \n",
       "9            9             0.0              0.1250   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  hard, important, presentation, tough, depressi...   \n",
       "1  reminder, bit, chill, display, lonely, histori...   \n",
       "2  reminder, bit, chill, display, lonely, histori...   \n",
       "3  information, close, chapter, understand, reali...   \n",
       "4  dark, average, recent, difficult, guide, curat...   \n",
       "5  informative, past, era, time, gem, view, tale,...   \n",
       "6  informative, past, era, time, gem, view, tale,...   \n",
       "7  reminder, bit, chill, display, lonely, histori...   \n",
       "8  informative, past, era, time, gem, view, tale,...   \n",
       "9  informative, past, era, time, gem, view, tale,...   \n",
       "\n",
       "                                                Text  \n",
       "0                    Sorry no - read the Bradt Guide  \n",
       "1                         Dusty and poorly displayed  \n",
       "2            Intersting stuff, but poor presentation  \n",
       "3                      Shocking but must be visited!  \n",
       "4                           Captivating and shocking  \n",
       "5  Probably a must see, but not much to keep you ...  \n",
       "6                             Grace gone a bit down.  \n",
       "7  Home to Lucy but overcrowded with Children and...  \n",
       "8                                 Hardly world class  \n",
       "9                                      Disappointing  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code assigns all concerned Text with their corresponding topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    92\n",
       "3.0    27\n",
       "1.0    26\n",
       "5.0    22\n",
       "4.0    21\n",
       "7.0    21\n",
       "6.0    20\n",
       "2.0    20\n",
       "Name: Dominant_Topic, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic['Dominant_Topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Probably a must see, but not much to keep you there',\n",
       "       'Grace gone a bit down.', 'Hardly world class', 'Disappointing',\n",
       "       'Visited the National Museum with Secret Island Ethiopia Tours',\n",
       "       'Chilling museum of a forgotten horror', 'Average Museum',\n",
       "       'very boring', 'Interesting but a Little Disappointing',\n",
       "       'Disappointed', 'Looking pretty tired',\n",
       "       'Its a summary of Ethiopias harrowing past',\n",
       "       'A harrowing if brief window on a difficult era for Ethiopia.',\n",
       "       'Sad and informative',\n",
       "       'Learn historical information about Ethiopia’s past.',\n",
       "       'So sad, but something we need to know about',\n",
       "       'Scary and sadden place to visit', 'A raw gem',\n",
       "       'Request a guide if you know little about the Dergs', 'Gruesome',\n",
       "       'Somewhat of a disappointment', 'Not much to see here',\n",
       "       'Sad thought.', 'Seriously, not good',\n",
       "       'SAD REFECECTION OF MANS INHUMANITY TO MAN', 'Disappointing',\n",
       "       'Disappointing', 'Disappointing', 'Tired', 'Tragic',\n",
       "       'Disappointing', 'Sad, Moving, and Informative', 'Disappointing',\n",
       "       'an average place to visit', 'And aunt Lucy is down there. ',\n",
       "       'Tired', 'Gruesome', 'Its a must see, but its not very good',\n",
       "       'Disappointing', 'very bad upkeep',\n",
       "       'Visit if you have time. Skip it if limited on time.',\n",
       "       'Very disappointed in this museum', 'Shocking',\n",
       "       'Very poor to be the National museum', 'Lucy and Not Much Else',\n",
       "       'Explicit exhibit of a gruesome time',\n",
       "       'Not much to see besides a replica of Lucy', 'very poor museum',\n",
       "       'Great small museum to a tragic era of history', 'Bloody Ethiopia',\n",
       "       'A sobering reminder of the not-so-distant past', 'Cozy Museum',\n",
       "       'Disappointing visit with Lucy', 'Not worth it ', 'Shocking',\n",
       "       'A rather tired museum',\n",
       "       'Go to see Lucy! (You could skip the rest if limited on time)',\n",
       "       'disappointed', 'Very sad...', 'Tired but informative',\n",
       "       'Not great', 'Not much to see',\n",
       "       'Not much else to see in Addis Ababa', 'Not so dusty',\n",
       "       'Informative but Horrible lighting ', 'Not very informative ',\n",
       "       'Tired museum', 'Must See even if disturbing',\n",
       "       'Clarity to the past...', 'Very sad', 'Disappointing',\n",
       "       'A sad place to bury Lucy', 'tired',\n",
       "       'A disturbing but valuable visit',\n",
       "       'Old Bones and views of the past', 'Hidden gem',\n",
       "       'not much to see but somewhere to go...', 'Arthur rambuid center',\n",
       "       'A waste of time', 'Some Real Curious Gems Here',\n",
       "       'I was a little disappointed',\n",
       "       'Interesting, informative and very sad', 'Lucy and not much else',\n",
       "       'A must see to understand Ethiopian recent past',\n",
       "       'Dark and gloomy', 'Bit old and dusty',\n",
       "       'Very different from other museum, a must visit', 'Not much. ',\n",
       "       'A glimpse into the military ruled era', 'Learn from humans past',\n",
       "       'Very mediocre EXCEPT for Lucy, et al', 'Disappointing '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic[df_dominant_topic['Dominant_Topic'] == 0]['Text'].values # Lack of Content - 92\n",
    "# df_dominant_topic[df_dominant_topic['Dominant_Topic'] == 1]['Text'].values # Expressing Sadness over History - 26\n",
    "# df_dominant_topic[df_dominant_topic['Dominant_Topic'] == 2]['Text'].values # Museum Curation Criticism - 20\n",
    "# df_dominant_topic[df_dominant_topic['Dominant_Topic'] == 3]['Text'].values # Expressing Sadness over History - 27\n",
    "# df_dominant_topic[df_dominant_topic['Dominant_Topic'] == 4]['Text'].values # Expressing Sadness over History - 21\n",
    "# df_dominant_topic[df_dominant_topic['Dominant_Topic'] == 5]['Text'].values # Museum Curation Criticism - 22\n",
    "# df_dominant_topic[df_dominant_topic['Dominant_Topic'] == 6]['Text'].values # Museum Curation Criticism - 20\n",
    "# df_dominant_topic[df_dominant_topic['Dominant_Topic'] == 7]['Text'].values # Accessibility Criticism - 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is the main evaluation part where each topic is assessed if it fits to an identifiable concept. You can interchange the found concepts with their corresponding topic number in the previous dataframe should you want the text to be already tagged with its topic concept. Of course, you can change the concepts found above should you find other identifiable ones.\n",
    "<br>\n",
    "<br>The full breakdown and analysis of the six (6) LDA Models for both Ethiopia and Kenya can be found here: \n",
    "<br>https://docs.google.com/spreadsheets/d/1QNwNS0qlDuJVTPZvwZiHFJX0_qMma_RER7AVe1lmWlo/edit?usp=sharing\n",
    "<br>\n",
    "<br>The notebooks for the six (6) LDA Models for both Ethiopia and Kenya are of the following format (in the EDA + Modelling folder):\n",
    "<li>Ethiopia - \"Ethiopia EDA + Model 4.x.2... .ipynb\" where x is from one (1) to six (6)</li>\n",
    "<li>Kenya - \"Kenya EDA + Model 4.x.2... .ipynb\" where x is from one (1) to six (6)</li>\n",
    "<br>There are also saved csv files containing the texts with their corresponding topics (though they are still numbered). The csv files for the six (6) LDA Models for both Ethiopia and Kenya are of the following format (in the EDA + Modelling folder):\n",
    "<li>Ethiopia - \"ethiopia_4x2.csv\" where x is from one (1) to six (6)</li>\n",
    "<li>Kenya - \"kenya_4x2.csv\" where x is from one (1) to six (6)</li>\n",
    "\n",
    "<br>You can change the topics within the csv files from numbers to concepts accordingly using the notebooks for the LDA models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1557</td>\n",
       "      <td>informative, past, era, time, gem, view, tale,...</td>\n",
       "      <td>Old Bones and views of the past</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1428</td>\n",
       "      <td>hard, important, presentation, tough, depressi...</td>\n",
       "      <td>Bad displays, fragmentary information that doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.1692</td>\n",
       "      <td>reminder, bit, chill, display, lonely, histori...</td>\n",
       "      <td>Home to Lucy but overcrowded with Children and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>dark, average, recent, difficult, guide, curat...</td>\n",
       "      <td>A Dark Past which is Recent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>small, time, regime, hide, forget, ancestor, t...</td>\n",
       "      <td>It is horrible reminder of the bloody regime o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>history, worth, topic, hidden, bone, city, acc...</td>\n",
       "      <td>Terrifying history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.1557</td>\n",
       "      <td>poorly, learn, closed, selam, nonetheless, rim...</td>\n",
       "      <td>Visit Lucy and Selam, but everything else is p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>information, close, chapter, understand, reali...</td>\n",
       "      <td>Dont understand the bad reviews</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Num  Topic_Perc_Contrib  \\\n",
       "0        0.0              0.1557   \n",
       "1        1.0              0.1428   \n",
       "2        2.0              0.1692   \n",
       "3        3.0              0.1587   \n",
       "4        4.0              0.1528   \n",
       "5        5.0              0.1587   \n",
       "6        6.0              0.1557   \n",
       "7        7.0              0.1587   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  informative, past, era, time, gem, view, tale,...   \n",
       "1  hard, important, presentation, tough, depressi...   \n",
       "2  reminder, bit, chill, display, lonely, histori...   \n",
       "3  dark, average, recent, difficult, guide, curat...   \n",
       "4  small, time, regime, hide, forget, ancestor, t...   \n",
       "5  history, worth, topic, hidden, bone, city, acc...   \n",
       "6  poorly, learn, closed, selam, nonetheless, rim...   \n",
       "7  information, close, chapter, understand, reali...   \n",
       "\n",
       "                                                Text  \n",
       "0                    Old Bones and views of the past  \n",
       "1  Bad displays, fragmentary information that doe...  \n",
       "2  Home to Lucy but overcrowded with Children and...  \n",
       "3                        A Dark Past which is Recent  \n",
       "4  It is horrible reminder of the bloody regime o...  \n",
       "5                                 Terrifying history  \n",
       "6  Visit Lucy and Selam, but everything else is p...  \n",
       "7                    Dont understand the bad reviews  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates a dataframe which shows the texts that are the main contributors for the eight (8) acquired topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Old Bones and views of the past',\n",
       "       'Bad displays, fragmentary information that does not exceed our middle school education ',\n",
       "       'Home to Lucy but overcrowded with Children and poor displays',\n",
       "       'A Dark Past which is Recent',\n",
       "       'It is horrible reminder of the bloody regime of the Derge regime',\n",
       "       'Terrifying history',\n",
       "       'Visit Lucy and Selam, but everything else is poorly organized',\n",
       "       'Dont understand the bad reviews'], dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_topics_sorteddf_mallet['Text'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
